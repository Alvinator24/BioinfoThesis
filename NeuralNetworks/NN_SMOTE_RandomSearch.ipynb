{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06f9b30d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Program Files\\Python311\\python.exe\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d02c83f8-05ee-46d0-990a-bd1940035841",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then import the required libraries\n",
    "import importlib\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "# Remove standalone keras imports and use tf.keras instead\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "# Update keras imports to use tf.keras\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "# Use tf.keras.models instead\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "348e6c47-f9b3-4674-8cb8-13c4deb51a27",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original columns: ['GeneSymbol', 'SingleValueType', 'TCGA-OL-A66H-01', 'TCGA-3C-AALK-01', 'TCGA-AC-A5EH-01', 'TCGA-EW-A2FW-01', 'TCGA-E9-A1R0-01', 'TCGA-AR-A1AJ-01', 'TCGA-AC-A62Y-01', 'TCGA-E9-A1QZ-01'] ...\n",
      "Column 'SingleValueType' has been removed successfully.\n",
      "CNV Matrix After Transpose and Header Fix: (888, 19277)\n",
      "\n",
      "DataFrame preview:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>GeneSymbol</th>\n",
       "      <th>RPS4Y2</th>\n",
       "      <th>RPS4Y1</th>\n",
       "      <th>TBL1Y</th>\n",
       "      <th>NLGN4Y</th>\n",
       "      <th>PRKY</th>\n",
       "      <th>PCDH11Y</th>\n",
       "      <th>TTTY20</th>\n",
       "      <th>GABRE</th>\n",
       "      <th>FTHL17</th>\n",
       "      <th>PORCN</th>\n",
       "      <th>...</th>\n",
       "      <th>EP300</th>\n",
       "      <th>DERL3</th>\n",
       "      <th>PLA2G3</th>\n",
       "      <th>TMPRSS6</th>\n",
       "      <th>MIR1281</th>\n",
       "      <th>GGT3P</th>\n",
       "      <th>UBE2L3</th>\n",
       "      <th>APOL5</th>\n",
       "      <th>SLC5A1</th>\n",
       "      <th>CDC42EP1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TCGA-3C-AAAU-01</th>\n",
       "      <td>0.527</td>\n",
       "      <td>0.57214</td>\n",
       "      <td>0.447925</td>\n",
       "      <td>0.052075</td>\n",
       "      <td>0.1233</td>\n",
       "      <td>0.0581</td>\n",
       "      <td>0.50125</td>\n",
       "      <td>0.377325</td>\n",
       "      <td>0.878033</td>\n",
       "      <td>0.365011</td>\n",
       "      <td>...</td>\n",
       "      <td>0.099</td>\n",
       "      <td>0.04835</td>\n",
       "      <td>0.7942</td>\n",
       "      <td>0.86505</td>\n",
       "      <td>0.099</td>\n",
       "      <td>0.8638</td>\n",
       "      <td>0.3368</td>\n",
       "      <td>0.928</td>\n",
       "      <td>0.1865</td>\n",
       "      <td>0.0178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-3C-AALI-01</th>\n",
       "      <td>0.6489</td>\n",
       "      <td>0.5074</td>\n",
       "      <td>0.426008</td>\n",
       "      <td>0.07245</td>\n",
       "      <td>0.8148</td>\n",
       "      <td>0.0836</td>\n",
       "      <td>0.473473</td>\n",
       "      <td>0.387325</td>\n",
       "      <td>0.758033</td>\n",
       "      <td>0.254889</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0617</td>\n",
       "      <td>0.38345</td>\n",
       "      <td>0.7698</td>\n",
       "      <td>0.8228</td>\n",
       "      <td>0.0617</td>\n",
       "      <td>0.8317</td>\n",
       "      <td>0.8098</td>\n",
       "      <td>0.8742</td>\n",
       "      <td>0.8993</td>\n",
       "      <td>0.0234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-3C-AALJ-01</th>\n",
       "      <td>0.6949</td>\n",
       "      <td>0.563733</td>\n",
       "      <td>0.464233</td>\n",
       "      <td>0.0675</td>\n",
       "      <td>0.7933</td>\n",
       "      <td>0.0627</td>\n",
       "      <td>0.45565</td>\n",
       "      <td>0.333725</td>\n",
       "      <td>0.6283</td>\n",
       "      <td>0.473433</td>\n",
       "      <td>...</td>\n",
       "      <td>0.075</td>\n",
       "      <td>0.4813</td>\n",
       "      <td>0.7681</td>\n",
       "      <td>0.8433</td>\n",
       "      <td>0.075</td>\n",
       "      <td>0.7911</td>\n",
       "      <td>0.44875</td>\n",
       "      <td>0.8888</td>\n",
       "      <td>0.739</td>\n",
       "      <td>0.031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-3C-AALK-01</th>\n",
       "      <td>0.5778</td>\n",
       "      <td>0.5722</td>\n",
       "      <td>0.50945</td>\n",
       "      <td>0.34105</td>\n",
       "      <td>0.6853</td>\n",
       "      <td>0.2694</td>\n",
       "      <td>0.5769</td>\n",
       "      <td>0.53885</td>\n",
       "      <td>0.9241</td>\n",
       "      <td>0.417256</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0856</td>\n",
       "      <td>0.5369</td>\n",
       "      <td>0.7532</td>\n",
       "      <td>0.83555</td>\n",
       "      <td>0.0856</td>\n",
       "      <td>0.8151</td>\n",
       "      <td>0.3113</td>\n",
       "      <td>0.9321</td>\n",
       "      <td>0.763</td>\n",
       "      <td>0.0274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-4H-AAAK-01</th>\n",
       "      <td>0.4716</td>\n",
       "      <td>0.5077</td>\n",
       "      <td>0.45365</td>\n",
       "      <td>0.063675</td>\n",
       "      <td>0.6571</td>\n",
       "      <td>0.3482</td>\n",
       "      <td>0.438033</td>\n",
       "      <td>0.480625</td>\n",
       "      <td>0.9169</td>\n",
       "      <td>0.469724</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0808</td>\n",
       "      <td>0.1768</td>\n",
       "      <td>0.6704</td>\n",
       "      <td>0.7699</td>\n",
       "      <td>0.0808</td>\n",
       "      <td>0.8049</td>\n",
       "      <td>0.2855</td>\n",
       "      <td>0.937</td>\n",
       "      <td>0.7207</td>\n",
       "      <td>0.0268</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 19277 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "GeneSymbol       RPS4Y2    RPS4Y1     TBL1Y    NLGN4Y    PRKY PCDH11Y  \\\n",
       "TCGA-3C-AAAU-01   0.527   0.57214  0.447925  0.052075  0.1233  0.0581   \n",
       "TCGA-3C-AALI-01  0.6489    0.5074  0.426008   0.07245  0.8148  0.0836   \n",
       "TCGA-3C-AALJ-01  0.6949  0.563733  0.464233    0.0675  0.7933  0.0627   \n",
       "TCGA-3C-AALK-01  0.5778    0.5722   0.50945   0.34105  0.6853  0.2694   \n",
       "TCGA-4H-AAAK-01  0.4716    0.5077   0.45365  0.063675  0.6571  0.3482   \n",
       "\n",
       "GeneSymbol         TTTY20     GABRE    FTHL17     PORCN  ...   EP300    DERL3  \\\n",
       "TCGA-3C-AAAU-01   0.50125  0.377325  0.878033  0.365011  ...   0.099  0.04835   \n",
       "TCGA-3C-AALI-01  0.473473  0.387325  0.758033  0.254889  ...  0.0617  0.38345   \n",
       "TCGA-3C-AALJ-01   0.45565  0.333725    0.6283  0.473433  ...   0.075   0.4813   \n",
       "TCGA-3C-AALK-01    0.5769   0.53885    0.9241  0.417256  ...  0.0856   0.5369   \n",
       "TCGA-4H-AAAK-01  0.438033  0.480625    0.9169  0.469724  ...  0.0808   0.1768   \n",
       "\n",
       "GeneSymbol       PLA2G3  TMPRSS6 MIR1281   GGT3P   UBE2L3   APOL5  SLC5A1  \\\n",
       "TCGA-3C-AAAU-01  0.7942  0.86505   0.099  0.8638   0.3368   0.928  0.1865   \n",
       "TCGA-3C-AALI-01  0.7698   0.8228  0.0617  0.8317   0.8098  0.8742  0.8993   \n",
       "TCGA-3C-AALJ-01  0.7681   0.8433   0.075  0.7911  0.44875  0.8888   0.739   \n",
       "TCGA-3C-AALK-01  0.7532  0.83555  0.0856  0.8151   0.3113  0.9321   0.763   \n",
       "TCGA-4H-AAAK-01  0.6704   0.7699  0.0808  0.8049   0.2855   0.937  0.7207   \n",
       "\n",
       "GeneSymbol      CDC42EP1  \n",
       "TCGA-3C-AAAU-01   0.0178  \n",
       "TCGA-3C-AALI-01   0.0234  \n",
       "TCGA-3C-AALJ-01    0.031  \n",
       "TCGA-3C-AALK-01   0.0274  \n",
       "TCGA-4H-AAAK-01   0.0268  \n",
       "\n",
       "[5 rows x 19277 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed = 0\n",
    "np.random.seed(seed)\n",
    "\n",
    "df = pd.read_csv('gene_level_methylation.csv')\n",
    "\n",
    "print(\"Original columns:\", df.columns.tolist()[:10], \"...\")\n",
    "\n",
    "# Remove the \"SingleValueType\" column if it exists\n",
    "if \"SingleValueType\" in df.columns:\n",
    "    df = df.drop(columns=[\"SingleValueType\"])\n",
    "    print(\"Column 'SingleValueType' has been removed successfully.\")\n",
    "else:\n",
    "    print(\"Column 'SingleValueType' does not exist in the DataFrame.\")\n",
    "\n",
    "# Sort columns and transpose\n",
    "df = df.reindex(sorted(df.columns), axis=1)\n",
    "df = df.T\n",
    "\n",
    "# Set first row (originally \"GeneSymbol\") as new column names\n",
    "df.columns = df.iloc[0]  # first row becomes column headers\n",
    "df = df.drop(df.index[0])  # drop the first row\n",
    "\n",
    "print(\"CNV Matrix After Transpose and Header Fix:\", df.shape)\n",
    "print(\"\\nDataFrame preview:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cef509c0-97a6-4354-9ec4-d5ac88c1b3f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clinical Data Before: (1247, 202)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AJCC_Stage_nature2012</th>\n",
       "      <th>Age_at_Initial_Pathologic_Diagnosis_nature2012</th>\n",
       "      <th>CN_Clusters_nature2012</th>\n",
       "      <th>Converted_Stage_nature2012</th>\n",
       "      <th>Days_to_Date_of_Last_Contact_nature2012</th>\n",
       "      <th>Days_to_date_of_Death_nature2012</th>\n",
       "      <th>ER_Status_nature2012</th>\n",
       "      <th>Gender_nature2012</th>\n",
       "      <th>HER2_Final_Status_nature2012</th>\n",
       "      <th>Integrated_Clusters_no_exp__nature2012</th>\n",
       "      <th>...</th>\n",
       "      <th>_GENOMIC_ID_TCGA_BRCA_mutation_wustl_gene</th>\n",
       "      <th>_GENOMIC_ID_TCGA_BRCA_miRNA_GA</th>\n",
       "      <th>_GENOMIC_ID_TCGA_BRCA_exp_HiSeqV2_percentile</th>\n",
       "      <th>_GENOMIC_ID_data/public/TCGA/BRCA/miRNA_GA_gene</th>\n",
       "      <th>_GENOMIC_ID_TCGA_BRCA_gistic2thd</th>\n",
       "      <th>_GENOMIC_ID_data/public/TCGA/BRCA/miRNA_HiSeq_gene</th>\n",
       "      <th>_GENOMIC_ID_TCGA_BRCA_G4502A_07_3</th>\n",
       "      <th>_GENOMIC_ID_TCGA_BRCA_exp_HiSeqV2</th>\n",
       "      <th>_GENOMIC_ID_TCGA_BRCA_gistic2</th>\n",
       "      <th>_GENOMIC_ID_TCGA_BRCA_PDMarray</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TCGA-A1-A0SB-01</th>\n",
       "      <td>Stage I</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Stage I</td>\n",
       "      <td>259.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Positive</td>\n",
       "      <td>FEMALE</td>\n",
       "      <td>Negative</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>TCGA-A1-A0SB-01A-11D-A142-09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>a2405d64-34eb-4915-abf7-8530151d5cb0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TCGA-A1-A0SB-01A-11D-A141-01</td>\n",
       "      <td>TCGA-A1-A0SB-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>a2405d64-34eb-4915-abf7-8530151d5cb0</td>\n",
       "      <td>TCGA-A1-A0SB-01A-11D-A141-01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-A1-A0SD-01</th>\n",
       "      <td>Stage IIA</td>\n",
       "      <td>59.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Stage IIA</td>\n",
       "      <td>437.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Positive</td>\n",
       "      <td>FEMALE</td>\n",
       "      <td>Negative</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>TCGA-A1-A0SD-01A-11D-A10Y-09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15bad71d-3031-413b-9e8d-6426ae5dfbea</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TCGA-A1-A0SD-01A-11D-A111-01</td>\n",
       "      <td>TCGA-A1-A0SD-01</td>\n",
       "      <td>TCGA-A1-A0SD-01A-11R-A115-07</td>\n",
       "      <td>15bad71d-3031-413b-9e8d-6426ae5dfbea</td>\n",
       "      <td>TCGA-A1-A0SD-01A-11D-A111-01</td>\n",
       "      <td>TCGA-A1-A0SD-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-A1-A0SE-01</th>\n",
       "      <td>Stage I</td>\n",
       "      <td>56.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Stage I</td>\n",
       "      <td>1320.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Positive</td>\n",
       "      <td>FEMALE</td>\n",
       "      <td>Negative</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>TCGA-A1-A0SE-01A-11D-A099-09</td>\n",
       "      <td>TCGA-A1-A0SE-01</td>\n",
       "      <td>a998e0ce-9248-460f-aabc-2dad452a1ff9</td>\n",
       "      <td>TCGA-A1-A0SE-01</td>\n",
       "      <td>TCGA-A1-A0SE-01A-11D-A087-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TCGA-A1-A0SE-01A-11R-A084-07</td>\n",
       "      <td>a998e0ce-9248-460f-aabc-2dad452a1ff9</td>\n",
       "      <td>TCGA-A1-A0SE-01A-11D-A087-01</td>\n",
       "      <td>TCGA-A1-A0SE-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-A1-A0SF-01</th>\n",
       "      <td>Stage IIA</td>\n",
       "      <td>54.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Stage IIA</td>\n",
       "      <td>1463.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Positive</td>\n",
       "      <td>FEMALE</td>\n",
       "      <td>Negative</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>TCGA-A1-A0SF-01A-11D-A142-09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28089e15-5e2c-4e83-ba6c-62b3cb40e431</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TCGA-A1-A0SF-01A-11D-A141-01</td>\n",
       "      <td>TCGA-A1-A0SF-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28089e15-5e2c-4e83-ba6c-62b3cb40e431</td>\n",
       "      <td>TCGA-A1-A0SF-01A-11D-A141-01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-A1-A0SG-01</th>\n",
       "      <td>Stage IIB</td>\n",
       "      <td>61.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Stage IIB</td>\n",
       "      <td>433.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Positive</td>\n",
       "      <td>FEMALE</td>\n",
       "      <td>Negative</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>TCGA-A1-A0SG-01A-11D-A142-09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0df6b948-367d-4951-9d98-d3bebabff63e</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TCGA-A1-A0SG-01A-11D-A141-01</td>\n",
       "      <td>TCGA-A1-A0SG-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0df6b948-367d-4951-9d98-d3bebabff63e</td>\n",
       "      <td>TCGA-A1-A0SG-01A-11D-A141-01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 202 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                AJCC_Stage_nature2012  \\\n",
       "TCGA-A1-A0SB-01               Stage I   \n",
       "TCGA-A1-A0SD-01             Stage IIA   \n",
       "TCGA-A1-A0SE-01               Stage I   \n",
       "TCGA-A1-A0SF-01             Stage IIA   \n",
       "TCGA-A1-A0SG-01             Stage IIB   \n",
       "\n",
       "                 Age_at_Initial_Pathologic_Diagnosis_nature2012  \\\n",
       "TCGA-A1-A0SB-01                                            70.0   \n",
       "TCGA-A1-A0SD-01                                            59.0   \n",
       "TCGA-A1-A0SE-01                                            56.0   \n",
       "TCGA-A1-A0SF-01                                            54.0   \n",
       "TCGA-A1-A0SG-01                                            61.0   \n",
       "\n",
       "                 CN_Clusters_nature2012 Converted_Stage_nature2012  \\\n",
       "TCGA-A1-A0SB-01                     1.0                    Stage I   \n",
       "TCGA-A1-A0SD-01                     2.0                  Stage IIA   \n",
       "TCGA-A1-A0SE-01                     2.0                    Stage I   \n",
       "TCGA-A1-A0SF-01                     3.0                  Stage IIA   \n",
       "TCGA-A1-A0SG-01                     4.0                  Stage IIB   \n",
       "\n",
       "                 Days_to_Date_of_Last_Contact_nature2012  \\\n",
       "TCGA-A1-A0SB-01                                    259.0   \n",
       "TCGA-A1-A0SD-01                                    437.0   \n",
       "TCGA-A1-A0SE-01                                   1320.0   \n",
       "TCGA-A1-A0SF-01                                   1463.0   \n",
       "TCGA-A1-A0SG-01                                    433.0   \n",
       "\n",
       "                 Days_to_date_of_Death_nature2012 ER_Status_nature2012  \\\n",
       "TCGA-A1-A0SB-01                               NaN             Positive   \n",
       "TCGA-A1-A0SD-01                               NaN             Positive   \n",
       "TCGA-A1-A0SE-01                               NaN             Positive   \n",
       "TCGA-A1-A0SF-01                               NaN             Positive   \n",
       "TCGA-A1-A0SG-01                               NaN             Positive   \n",
       "\n",
       "                Gender_nature2012 HER2_Final_Status_nature2012  \\\n",
       "TCGA-A1-A0SB-01            FEMALE                     Negative   \n",
       "TCGA-A1-A0SD-01            FEMALE                     Negative   \n",
       "TCGA-A1-A0SE-01            FEMALE                     Negative   \n",
       "TCGA-A1-A0SF-01            FEMALE                     Negative   \n",
       "TCGA-A1-A0SG-01            FEMALE                     Negative   \n",
       "\n",
       "                 Integrated_Clusters_no_exp__nature2012  ...  \\\n",
       "TCGA-A1-A0SB-01                                     NaN  ...   \n",
       "TCGA-A1-A0SD-01                                     NaN  ...   \n",
       "TCGA-A1-A0SE-01                                     NaN  ...   \n",
       "TCGA-A1-A0SF-01                                     NaN  ...   \n",
       "TCGA-A1-A0SG-01                                     NaN  ...   \n",
       "\n",
       "                 _GENOMIC_ID_TCGA_BRCA_mutation_wustl_gene  \\\n",
       "TCGA-A1-A0SB-01               TCGA-A1-A0SB-01A-11D-A142-09   \n",
       "TCGA-A1-A0SD-01               TCGA-A1-A0SD-01A-11D-A10Y-09   \n",
       "TCGA-A1-A0SE-01               TCGA-A1-A0SE-01A-11D-A099-09   \n",
       "TCGA-A1-A0SF-01               TCGA-A1-A0SF-01A-11D-A142-09   \n",
       "TCGA-A1-A0SG-01               TCGA-A1-A0SG-01A-11D-A142-09   \n",
       "\n",
       "                 _GENOMIC_ID_TCGA_BRCA_miRNA_GA  \\\n",
       "TCGA-A1-A0SB-01                             NaN   \n",
       "TCGA-A1-A0SD-01                             NaN   \n",
       "TCGA-A1-A0SE-01                 TCGA-A1-A0SE-01   \n",
       "TCGA-A1-A0SF-01                             NaN   \n",
       "TCGA-A1-A0SG-01                             NaN   \n",
       "\n",
       "                _GENOMIC_ID_TCGA_BRCA_exp_HiSeqV2_percentile  \\\n",
       "TCGA-A1-A0SB-01         a2405d64-34eb-4915-abf7-8530151d5cb0   \n",
       "TCGA-A1-A0SD-01         15bad71d-3031-413b-9e8d-6426ae5dfbea   \n",
       "TCGA-A1-A0SE-01         a998e0ce-9248-460f-aabc-2dad452a1ff9   \n",
       "TCGA-A1-A0SF-01         28089e15-5e2c-4e83-ba6c-62b3cb40e431   \n",
       "TCGA-A1-A0SG-01         0df6b948-367d-4951-9d98-d3bebabff63e   \n",
       "\n",
       "                _GENOMIC_ID_data/public/TCGA/BRCA/miRNA_GA_gene  \\\n",
       "TCGA-A1-A0SB-01                                             NaN   \n",
       "TCGA-A1-A0SD-01                                             NaN   \n",
       "TCGA-A1-A0SE-01                                 TCGA-A1-A0SE-01   \n",
       "TCGA-A1-A0SF-01                                             NaN   \n",
       "TCGA-A1-A0SG-01                                             NaN   \n",
       "\n",
       "                _GENOMIC_ID_TCGA_BRCA_gistic2thd  \\\n",
       "TCGA-A1-A0SB-01     TCGA-A1-A0SB-01A-11D-A141-01   \n",
       "TCGA-A1-A0SD-01     TCGA-A1-A0SD-01A-11D-A111-01   \n",
       "TCGA-A1-A0SE-01     TCGA-A1-A0SE-01A-11D-A087-01   \n",
       "TCGA-A1-A0SF-01     TCGA-A1-A0SF-01A-11D-A141-01   \n",
       "TCGA-A1-A0SG-01     TCGA-A1-A0SG-01A-11D-A141-01   \n",
       "\n",
       "                _GENOMIC_ID_data/public/TCGA/BRCA/miRNA_HiSeq_gene  \\\n",
       "TCGA-A1-A0SB-01                                    TCGA-A1-A0SB-01   \n",
       "TCGA-A1-A0SD-01                                    TCGA-A1-A0SD-01   \n",
       "TCGA-A1-A0SE-01                                                NaN   \n",
       "TCGA-A1-A0SF-01                                    TCGA-A1-A0SF-01   \n",
       "TCGA-A1-A0SG-01                                    TCGA-A1-A0SG-01   \n",
       "\n",
       "                 _GENOMIC_ID_TCGA_BRCA_G4502A_07_3  \\\n",
       "TCGA-A1-A0SB-01                                NaN   \n",
       "TCGA-A1-A0SD-01       TCGA-A1-A0SD-01A-11R-A115-07   \n",
       "TCGA-A1-A0SE-01       TCGA-A1-A0SE-01A-11R-A084-07   \n",
       "TCGA-A1-A0SF-01                                NaN   \n",
       "TCGA-A1-A0SG-01                                NaN   \n",
       "\n",
       "                    _GENOMIC_ID_TCGA_BRCA_exp_HiSeqV2  \\\n",
       "TCGA-A1-A0SB-01  a2405d64-34eb-4915-abf7-8530151d5cb0   \n",
       "TCGA-A1-A0SD-01  15bad71d-3031-413b-9e8d-6426ae5dfbea   \n",
       "TCGA-A1-A0SE-01  a998e0ce-9248-460f-aabc-2dad452a1ff9   \n",
       "TCGA-A1-A0SF-01  28089e15-5e2c-4e83-ba6c-62b3cb40e431   \n",
       "TCGA-A1-A0SG-01  0df6b948-367d-4951-9d98-d3bebabff63e   \n",
       "\n",
       "                _GENOMIC_ID_TCGA_BRCA_gistic2 _GENOMIC_ID_TCGA_BRCA_PDMarray  \n",
       "TCGA-A1-A0SB-01  TCGA-A1-A0SB-01A-11D-A141-01                            NaN  \n",
       "TCGA-A1-A0SD-01  TCGA-A1-A0SD-01A-11D-A111-01                TCGA-A1-A0SD-01  \n",
       "TCGA-A1-A0SE-01  TCGA-A1-A0SE-01A-11D-A087-01                TCGA-A1-A0SE-01  \n",
       "TCGA-A1-A0SF-01  TCGA-A1-A0SF-01A-11D-A141-01                            NaN  \n",
       "TCGA-A1-A0SG-01  TCGA-A1-A0SG-01A-11D-A141-01                            NaN  \n",
       "\n",
       "[5 rows x 202 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2=pd.read_csv('BRCA_clinicalMatrix.gz',compression='gzip',sep='\\t',index_col=0)\n",
    "df2.index = pd.Series({x: x.replace('-', '-') for x in df2.index})\n",
    "print(\"Clinical Data Before:\", df2.shape)\n",
    "k=df2.columns.get_loc('PAM50Call_RNAseq')\n",
    "df2=df2[df2.iloc[:,k].isna()==False]\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e78c03fd-abfd-42c0-a2db-3e67c7c332cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data After: (620, 19277)\n",
      "Clinical Data After: (620, 202)\n",
      "CNV and Clinical Data corresponds to same Patients:  True\n",
      "Labels ['Basal' 'Her2' 'LumA' 'LumB' 'Normal'] [ 87  31 288 127  87]\n"
     ]
    }
   ],
   "source": [
    "commonIndexes=np.sort(list(set(df2.index).intersection(set(df.index)))) \n",
    "df=df.loc[commonIndexes] \n",
    "df2=df2.loc[commonIndexes] \n",
    "print(\"Data After:\", df.shape) \n",
    "print(\"Clinical Data After:\", df2.shape) \n",
    "print(\"CNV and Clinical Data corresponds to same Patients: \", False if False in (df.index==df2.index) else True) \n",
    "unique_elements, counts_elements = np.unique(df2.iloc[:,k], return_counts=True) \n",
    "print(\"Labels\", unique_elements, counts_elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "978a01a9-a906-4d4a-8983-ae3e34710ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#all genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "682a6675-d9e9-423a-a6b1-b2bc2a75e3c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(620,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_feature_names = df.columns.tolist()\n",
    "X=np.array(df.values, dtype=float)\n",
    "X.shape\n",
    "Y=np.array(df2.values[:,k])\n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e6ffd47a-43d0-4171-a702-08d504b21979",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "n_splits = 5\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8a3c1439-e5c0-4c71-8a4c-f9903793cdb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((496, 19277), (124, 19277))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folds = list(skf.split(X, Y))\n",
    "\n",
    "# Select fold 4\n",
    "train_idx, test_idx = folds[4]\n",
    "X_train, X_test = X[train_idx], X[test_idx]\n",
    "Y_train, Y_test = Y[train_idx], Y[test_idx]\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c7036be7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature matrix shape: (620, 19277)\n",
      "Labels shape: (620,)\n",
      "Classes: ['Basal' 'Her2' 'LumA' 'LumB' 'Normal']\n"
     ]
    }
   ],
   "source": [
    "# Define features (X) and labels (y)\n",
    "X = df.values.astype(float)    # features must be numeric\n",
    "y = df2.iloc[:, k].values      # PAM50 labels\n",
    "original_feature_names = df.columns.tolist()\n",
    "\n",
    "print(\"Feature matrix shape:\", X.shape)\n",
    "print(\"Labels shape:\", y.shape)\n",
    "print(\"Classes:\", np.unique(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b22b46ce-2ab6-412a-9fa1-684af292674b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input dimensions: 19277\n",
      "Number of classes: 5\n",
      "Starting hyperparameter search...\n",
      "Total possible combinations: 5760 = 5760\n",
      "Testing 50 random combinations with 3-fold CV = 150 model trainings\n",
      "\n",
      "Fitting 2 folds for each of 50 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mike\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\layers\\core\\dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END nn__batch_size=16, nn__model__activation=relu, nn__model__dropout_rate=0.2, nn__model__learning_rate=0.001, nn__model__regularization=l2;, score=(train=0.781, test=0.727) total time=  36.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mike\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\layers\\core\\dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END nn__batch_size=16, nn__model__activation=relu, nn__model__dropout_rate=0.2, nn__model__learning_rate=0.001, nn__model__regularization=l2;, score=(train=0.782, test=0.658) total time=  58.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mike\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\layers\\core\\dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END nn__batch_size=64, nn__model__activation=<LeakyReLU name=leaky_re_lu, built=True>, nn__model__dropout_rate=0.5, nn__model__learning_rate=0.002, nn__model__regularization=l1;, score=(train=0.166, test=0.219) total time=  27.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mike\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\layers\\core\\dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END nn__batch_size=64, nn__model__activation=<LeakyReLU name=leaky_re_lu, built=True>, nn__model__dropout_rate=0.5, nn__model__learning_rate=0.002, nn__model__regularization=l1;, score=(train=0.511, test=0.480) total time=  15.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mike\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\layers\\core\\dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 15 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x0000027C87A36660> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "[CV 1/2] END nn__batch_size=128, nn__model__activation=tanh, nn__model__dropout_rate=0.3, nn__model__learning_rate=0.001, nn__model__regularization=None;, score=(train=0.206, test=0.177) total time=  17.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mike\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\layers\\core\\dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 13 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x0000027C6CA37560> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "[CV 2/2] END nn__batch_size=128, nn__model__activation=tanh, nn__model__dropout_rate=0.3, nn__model__learning_rate=0.001, nn__model__regularization=None;, score=(train=0.047, test=0.097) total time=   5.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mike\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\layers\\core\\dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END nn__batch_size=16, nn__model__activation=<LeakyReLU name=leaky_re_lu, built=True>, nn__model__dropout_rate=0.4, nn__model__learning_rate=1e-06, nn__model__regularization=l1;, score=(train=0.781, test=0.700) total time= 2.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mike\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\layers\\core\\dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END nn__batch_size=16, nn__model__activation=<LeakyReLU name=leaky_re_lu, built=True>, nn__model__dropout_rate=0.4, nn__model__learning_rate=1e-06, nn__model__regularization=l1;, score=(train=0.736, test=0.621) total time= 2.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mike\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\layers\\core\\dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END nn__batch_size=16, nn__model__activation=tanh, nn__model__dropout_rate=0.1, nn__model__learning_rate=1e-06, nn__model__regularization=l1;, score=(train=0.810, test=0.751) total time= 2.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mike\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\layers\\core\\dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END nn__batch_size=16, nn__model__activation=tanh, nn__model__dropout_rate=0.1, nn__model__learning_rate=1e-06, nn__model__regularization=l1;, score=(train=0.842, test=0.686) total time= 2.4min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mike\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\layers\\core\\dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END nn__batch_size=32, nn__model__activation=relu, nn__model__dropout_rate=0.1, nn__model__learning_rate=0.002, nn__model__regularization=None;, score=(train=0.656, test=0.552) total time=  15.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mike\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\layers\\core\\dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END nn__batch_size=32, nn__model__activation=relu, nn__model__dropout_rate=0.1, nn__model__learning_rate=0.002, nn__model__regularization=None;, score=(train=0.796, test=0.611) total time=  19.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mike\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\layers\\core\\dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END nn__batch_size=32, nn__model__activation=tanh, nn__model__dropout_rate=0.3, nn__model__learning_rate=1e-06, nn__model__regularization=None;, score=(train=0.794, test=0.723) total time=  54.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mike\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\layers\\core\\dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END nn__batch_size=32, nn__model__activation=tanh, nn__model__dropout_rate=0.3, nn__model__learning_rate=1e-06, nn__model__regularization=None;, score=(train=0.810, test=0.657) total time= 1.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mike\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\layers\\core\\dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END nn__batch_size=16, nn__model__activation=<LeakyReLU name=leaky_re_lu, built=True>, nn__model__dropout_rate=0.2, nn__model__learning_rate=0.0001, nn__model__regularization=l2;, score=(train=0.988, test=0.789) total time= 2.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mike\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\layers\\core\\dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END nn__batch_size=16, nn__model__activation=<LeakyReLU name=leaky_re_lu, built=True>, nn__model__dropout_rate=0.2, nn__model__learning_rate=0.0001, nn__model__regularization=l2;, score=(train=0.965, test=0.707) total time= 2.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mike\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\layers\\core\\dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END nn__batch_size=32, nn__model__activation=relu, nn__model__dropout_rate=0.5, nn__model__learning_rate=0.001, nn__model__regularization=l1_l2;, score=(train=0.248, test=0.341) total time=  19.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mike\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\layers\\core\\dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END nn__batch_size=32, nn__model__activation=relu, nn__model__dropout_rate=0.5, nn__model__learning_rate=0.001, nn__model__regularization=l1_l2;, score=(train=0.594, test=0.434) total time=  57.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mike\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\layers\\core\\dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END nn__batch_size=128, nn__model__activation=relu, nn__model__dropout_rate=0.2, nn__model__learning_rate=1e-06, nn__model__regularization=l1_l2;, score=(train=0.565, test=0.533) total time=  33.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mike\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\layers\\core\\dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END nn__batch_size=128, nn__model__activation=relu, nn__model__dropout_rate=0.2, nn__model__learning_rate=1e-06, nn__model__regularization=l1_l2;, score=(train=0.561, test=0.591) total time=  34.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mike\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\layers\\core\\dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END nn__batch_size=32, nn__model__activation=<LeakyReLU name=leaky_re_lu, built=True>, nn__model__dropout_rate=0.4, nn__model__learning_rate=0.002, nn__model__regularization=l1_l2;, score=(train=0.821, test=0.755) total time=  40.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mike\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\layers\\core\\dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END nn__batch_size=32, nn__model__activation=<LeakyReLU name=leaky_re_lu, built=True>, nn__model__dropout_rate=0.4, nn__model__learning_rate=0.002, nn__model__regularization=l1_l2;, score=(train=0.753, test=0.653) total time= 1.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mike\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\layers\\core\\dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END nn__batch_size=32, nn__model__activation=<LeakyReLU name=leaky_re_lu, built=True>, nn__model__dropout_rate=0.2, nn__model__learning_rate=1e-05, nn__model__regularization=l2;, score=(train=0.931, test=0.799) total time= 1.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mike\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\layers\\core\\dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END nn__batch_size=32, nn__model__activation=<LeakyReLU name=leaky_re_lu, built=True>, nn__model__dropout_rate=0.2, nn__model__learning_rate=1e-05, nn__model__regularization=l2;, score=(train=0.940, test=0.697) total time= 1.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mike\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\layers\\core\\dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END nn__batch_size=16, nn__model__activation=tanh, nn__model__dropout_rate=0.2, nn__model__learning_rate=0.001, nn__model__regularization=None;, score=(train=0.033, test=0.037) total time=  31.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mike\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\layers\\core\\dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END nn__batch_size=16, nn__model__activation=tanh, nn__model__dropout_rate=0.2, nn__model__learning_rate=0.001, nn__model__regularization=None;, score=(train=0.037, test=0.033) total time= 1.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mike\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\layers\\core\\dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END nn__batch_size=32, nn__model__activation=<LeakyReLU name=leaky_re_lu, built=True>, nn__model__dropout_rate=0.4, nn__model__learning_rate=0.0001, nn__model__regularization=l2;, score=(train=0.952, test=0.806) total time= 1.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mike\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\layers\\core\\dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END nn__batch_size=32, nn__model__activation=<LeakyReLU name=leaky_re_lu, built=True>, nn__model__dropout_rate=0.4, nn__model__learning_rate=0.0001, nn__model__regularization=l2;, score=(train=0.956, test=0.742) total time= 1.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mike\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\layers\\core\\dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END nn__batch_size=128, nn__model__activation=<LeakyReLU name=leaky_re_lu, built=True>, nn__model__dropout_rate=0.3, nn__model__learning_rate=0.0001, nn__model__regularization=None;, score=(train=0.854, test=0.768) total time=  23.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mike\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\layers\\core\\dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END nn__batch_size=128, nn__model__activation=<LeakyReLU name=leaky_re_lu, built=True>, nn__model__dropout_rate=0.3, nn__model__learning_rate=0.0001, nn__model__regularization=None;, score=(train=0.964, test=0.733) total time=  24.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mike\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\layers\\core\\dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END nn__batch_size=16, nn__model__activation=<LeakyReLU name=leaky_re_lu, built=True>, nn__model__dropout_rate=0.2, nn__model__learning_rate=0.002, nn__model__regularization=None;, score=(train=0.923, test=0.793) total time=  57.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mike\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\layers\\core\\dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END nn__batch_size=16, nn__model__activation=<LeakyReLU name=leaky_re_lu, built=True>, nn__model__dropout_rate=0.2, nn__model__learning_rate=0.002, nn__model__regularization=None;, score=(train=0.801, test=0.688) total time=  39.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mike\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\layers\\core\\dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END nn__batch_size=32, nn__model__activation=<LeakyReLU name=leaky_re_lu, built=True>, nn__model__dropout_rate=0.5, nn__model__learning_rate=1e-06, nn__model__regularization=None;, score=(train=0.686, test=0.640) total time=  53.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mike\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\layers\\core\\dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END nn__batch_size=32, nn__model__activation=<LeakyReLU name=leaky_re_lu, built=True>, nn__model__dropout_rate=0.5, nn__model__learning_rate=1e-06, nn__model__regularization=None;, score=(train=0.724, test=0.581) total time= 1.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mike\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\layers\\core\\dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END nn__batch_size=64, nn__model__activation=<LeakyReLU name=leaky_re_lu, built=True>, nn__model__dropout_rate=0.2, nn__model__learning_rate=0.01, nn__model__regularization=None;, score=(train=0.660, test=0.728) total time=  21.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mike\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\layers\\core\\dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END nn__batch_size=64, nn__model__activation=<LeakyReLU name=leaky_re_lu, built=True>, nn__model__dropout_rate=0.2, nn__model__learning_rate=0.01, nn__model__regularization=None;, score=(train=0.876, test=0.726) total time=  19.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mike\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\layers\\core\\dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END nn__batch_size=64, nn__model__activation=<LeakyReLU name=leaky_re_lu, built=True>, nn__model__dropout_rate=0.3, nn__model__learning_rate=0.002, nn__model__regularization=l2;, score=(train=0.650, test=0.712) total time=  17.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mike\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\layers\\core\\dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END nn__batch_size=64, nn__model__activation=<LeakyReLU name=leaky_re_lu, built=True>, nn__model__dropout_rate=0.3, nn__model__learning_rate=0.002, nn__model__regularization=l2;, score=(train=0.839, test=0.700) total time=  17.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mike\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\layers\\core\\dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END nn__batch_size=128, nn__model__activation=tanh, nn__model__dropout_rate=0.5, nn__model__learning_rate=0.01, nn__model__regularization=l1;, score=(train=0.028, test=0.043) total time=  10.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mike\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\layers\\core\\dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END nn__batch_size=128, nn__model__activation=tanh, nn__model__dropout_rate=0.5, nn__model__learning_rate=0.01, nn__model__regularization=l1;, score=(train=0.342, test=0.248) total time=  10.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mike\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\layers\\core\\dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END nn__batch_size=16, nn__model__activation=tanh, nn__model__dropout_rate=0.3, nn__model__learning_rate=0.0001, nn__model__regularization=l2;, score=(train=0.912, test=0.796) total time= 1.7min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mike\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\layers\\core\\dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END nn__batch_size=16, nn__model__activation=tanh, nn__model__dropout_rate=0.3, nn__model__learning_rate=0.0001, nn__model__regularization=l2;, score=(train=0.976, test=0.703) total time= 2.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mike\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\layers\\core\\dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END nn__batch_size=16, nn__model__activation=<LeakyReLU name=leaky_re_lu, built=True>, nn__model__dropout_rate=0.1, nn__model__learning_rate=0.0001, nn__model__regularization=l2;, score=(train=0.980, test=0.803) total time= 1.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mike\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\layers\\core\\dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END nn__batch_size=16, nn__model__activation=<LeakyReLU name=leaky_re_lu, built=True>, nn__model__dropout_rate=0.1, nn__model__learning_rate=0.0001, nn__model__regularization=l2;, score=(train=0.996, test=0.706) total time= 2.4min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mike\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\layers\\core\\dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END nn__batch_size=32, nn__model__activation=<LeakyReLU name=leaky_re_lu, built=True>, nn__model__dropout_rate=0.3, nn__model__learning_rate=0.01, nn__model__regularization=l1_l2;, score=(train=0.489, test=0.464) total time=  25.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mike\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\layers\\core\\dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END nn__batch_size=32, nn__model__activation=<LeakyReLU name=leaky_re_lu, built=True>, nn__model__dropout_rate=0.3, nn__model__learning_rate=0.01, nn__model__regularization=l1_l2;, score=(train=0.724, test=0.625) total time=  46.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mike\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\layers\\core\\dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END nn__batch_size=128, nn__model__activation=<LeakyReLU name=leaky_re_lu, built=True>, nn__model__dropout_rate=0.5, nn__model__learning_rate=0.002, nn__model__regularization=l1;, score=(train=0.363, test=0.302) total time=  21.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mike\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\layers\\core\\dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END nn__batch_size=128, nn__model__activation=<LeakyReLU name=leaky_re_lu, built=True>, nn__model__dropout_rate=0.5, nn__model__learning_rate=0.002, nn__model__regularization=l1;, score=(train=0.797, test=0.706) total time=  15.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mike\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\layers\\core\\dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END nn__batch_size=128, nn__model__activation=<LeakyReLU name=leaky_re_lu, built=True>, nn__model__dropout_rate=0.4, nn__model__learning_rate=1e-05, nn__model__regularization=l1;, score=(train=0.748, test=0.725) total time=  29.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mike\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\layers\\core\\dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END nn__batch_size=128, nn__model__activation=<LeakyReLU name=leaky_re_lu, built=True>, nn__model__dropout_rate=0.4, nn__model__learning_rate=1e-05, nn__model__regularization=l1;, score=(train=0.861, test=0.706) total time=  30.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mike\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\layers\\core\\dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END nn__batch_size=64, nn__model__activation=tanh, nn__model__dropout_rate=0.1, nn__model__learning_rate=0.0001, nn__model__regularization=l1;, score=(train=0.956, test=0.798) total time=  30.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mike\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\layers\\core\\dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END nn__batch_size=64, nn__model__activation=tanh, nn__model__dropout_rate=0.1, nn__model__learning_rate=0.0001, nn__model__regularization=l1;, score=(train=0.988, test=0.707) total time=  47.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mike\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\layers\\core\\dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END nn__batch_size=16, nn__model__activation=tanh, nn__model__dropout_rate=0.1, nn__model__learning_rate=1e-06, nn__model__regularization=l2;, score=(train=0.838, test=0.762) total time= 2.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mike\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\layers\\core\\dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END nn__batch_size=16, nn__model__activation=tanh, nn__model__dropout_rate=0.1, nn__model__learning_rate=1e-06, nn__model__regularization=l2;, score=(train=0.879, test=0.717) total time= 2.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mike\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\layers\\core\\dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END nn__batch_size=16, nn__model__activation=tanh, nn__model__dropout_rate=0.5, nn__model__learning_rate=0.001, nn__model__regularization=None;, score=(train=0.028, test=0.043) total time= 1.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mike\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\layers\\core\\dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END nn__batch_size=16, nn__model__activation=tanh, nn__model__dropout_rate=0.5, nn__model__learning_rate=0.001, nn__model__regularization=None;, score=(train=0.001, test=0.010) total time= 1.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mike\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\layers\\core\\dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END nn__batch_size=64, nn__model__activation=<LeakyReLU name=leaky_re_lu, built=True>, nn__model__dropout_rate=0.4, nn__model__learning_rate=1e-06, nn__model__regularization=l2;, score=(train=0.617, test=0.576) total time=  42.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mike\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\layers\\core\\dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END nn__batch_size=64, nn__model__activation=<LeakyReLU name=leaky_re_lu, built=True>, nn__model__dropout_rate=0.4, nn__model__learning_rate=1e-06, nn__model__regularization=l2;, score=(train=0.649, test=0.583) total time=  47.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mike\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\layers\\core\\dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END nn__batch_size=16, nn__model__activation=tanh, nn__model__dropout_rate=0.5, nn__model__learning_rate=0.002, nn__model__regularization=l1_l2;, score=(train=0.097, test=0.047) total time= 1.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mike\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\layers\\core\\dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END nn__batch_size=16, nn__model__activation=tanh, nn__model__dropout_rate=0.5, nn__model__learning_rate=0.002, nn__model__regularization=l1_l2;, score=(train=0.043, test=0.028) total time= 1.4min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mike\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\layers\\core\\dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END nn__batch_size=16, nn__model__activation=relu, nn__model__dropout_rate=0.2, nn__model__learning_rate=0.002, nn__model__regularization=l1_l2;, score=(train=0.530, test=0.614) total time=  22.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mike\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\layers\\core\\dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END nn__batch_size=16, nn__model__activation=relu, nn__model__dropout_rate=0.2, nn__model__learning_rate=0.002, nn__model__regularization=l1_l2;, score=(train=0.830, test=0.623) total time=  46.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mike\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\layers\\core\\dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END nn__batch_size=16, nn__model__activation=tanh, nn__model__dropout_rate=0.4, nn__model__learning_rate=0.001, nn__model__regularization=l2;, score=(train=0.028, test=0.043) total time= 1.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mike\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\layers\\core\\dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END nn__batch_size=16, nn__model__activation=tanh, nn__model__dropout_rate=0.4, nn__model__learning_rate=0.001, nn__model__regularization=l2;, score=(train=0.001, test=0.010) total time= 1.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mike\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\layers\\core\\dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END nn__batch_size=64, nn__model__activation=<LeakyReLU name=leaky_re_lu, built=True>, nn__model__dropout_rate=0.3, nn__model__learning_rate=1e-05, nn__model__regularization=l2;, score=(train=0.843, test=0.746) total time=  42.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mike\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\layers\\core\\dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END nn__batch_size=64, nn__model__activation=<LeakyReLU name=leaky_re_lu, built=True>, nn__model__dropout_rate=0.3, nn__model__learning_rate=1e-05, nn__model__regularization=l2;, score=(train=0.880, test=0.727) total time=  46.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mike\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\layers\\core\\dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END nn__batch_size=16, nn__model__activation=<LeakyReLU name=leaky_re_lu, built=True>, nn__model__dropout_rate=0.3, nn__model__learning_rate=0.001, nn__model__regularization=l1_l2;, score=(train=0.862, test=0.787) total time= 1.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mike\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\layers\\core\\dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END nn__batch_size=16, nn__model__activation=<LeakyReLU name=leaky_re_lu, built=True>, nn__model__dropout_rate=0.3, nn__model__learning_rate=0.001, nn__model__regularization=l1_l2;, score=(train=0.387, test=0.357) total time= 1.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mike\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\layers\\core\\dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END nn__batch_size=64, nn__model__activation=<LeakyReLU name=leaky_re_lu, built=True>, nn__model__dropout_rate=0.5, nn__model__learning_rate=0.01, nn__model__regularization=l2;, score=(train=0.322, test=0.486) total time=  21.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mike\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\layers\\core\\dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END nn__batch_size=64, nn__model__activation=<LeakyReLU name=leaky_re_lu, built=True>, nn__model__dropout_rate=0.5, nn__model__learning_rate=0.01, nn__model__regularization=l2;, score=(train=0.667, test=0.486) total time=  17.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mike\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\layers\\core\\dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END nn__batch_size=32, nn__model__activation=<LeakyReLU name=leaky_re_lu, built=True>, nn__model__dropout_rate=0.5, nn__model__learning_rate=1e-05, nn__model__regularization=l1;, score=(train=0.891, test=0.780) total time= 1.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mike\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\layers\\core\\dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END nn__batch_size=32, nn__model__activation=<LeakyReLU name=leaky_re_lu, built=True>, nn__model__dropout_rate=0.5, nn__model__learning_rate=1e-05, nn__model__regularization=l1;, score=(train=0.884, test=0.734) total time= 1.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mike\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\layers\\core\\dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END nn__batch_size=128, nn__model__activation=relu, nn__model__dropout_rate=0.2, nn__model__learning_rate=0.0001, nn__model__regularization=None;, score=(train=0.883, test=0.792) total time=  24.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mike\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\layers\\core\\dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END nn__batch_size=128, nn__model__activation=relu, nn__model__dropout_rate=0.2, nn__model__learning_rate=0.0001, nn__model__regularization=None;, score=(train=0.976, test=0.727) total time=  25.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mike\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\layers\\core\\dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END nn__batch_size=64, nn__model__activation=relu, nn__model__dropout_rate=0.5, nn__model__learning_rate=1e-06, nn__model__regularization=l2;, score=(train=0.663, test=0.588) total time=  42.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mike\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\layers\\core\\dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END nn__batch_size=64, nn__model__activation=relu, nn__model__dropout_rate=0.5, nn__model__learning_rate=1e-06, nn__model__regularization=l2;, score=(train=0.455, test=0.441) total time=  46.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mike\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\layers\\core\\dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END nn__batch_size=16, nn__model__activation=relu, nn__model__dropout_rate=0.5, nn__model__learning_rate=0.001, nn__model__regularization=l1_l2;, score=(train=0.194, test=0.150) total time=  19.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mike\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\layers\\core\\dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END nn__batch_size=16, nn__model__activation=relu, nn__model__dropout_rate=0.5, nn__model__learning_rate=0.001, nn__model__regularization=l1_l2;, score=(train=0.037, test=0.033) total time=  48.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mike\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\layers\\core\\dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END nn__batch_size=32, nn__model__activation=relu, nn__model__dropout_rate=0.5, nn__model__learning_rate=1e-06, nn__model__regularization=l1;, score=(train=0.631, test=0.646) total time=  52.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mike\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\layers\\core\\dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END nn__batch_size=32, nn__model__activation=relu, nn__model__dropout_rate=0.5, nn__model__learning_rate=1e-06, nn__model__regularization=l1;, score=(train=0.755, test=0.610) total time= 1.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mike\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\layers\\core\\dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END nn__batch_size=16, nn__model__activation=relu, nn__model__dropout_rate=0.1, nn__model__learning_rate=0.002, nn__model__regularization=None;, score=(train=0.522, test=0.489) total time=  26.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mike\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\layers\\core\\dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END nn__batch_size=16, nn__model__activation=relu, nn__model__dropout_rate=0.1, nn__model__learning_rate=0.002, nn__model__regularization=None;, score=(train=0.742, test=0.528) total time=  35.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mike\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\layers\\core\\dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END nn__batch_size=16, nn__model__activation=relu, nn__model__dropout_rate=0.3, nn__model__learning_rate=0.002, nn__model__regularization=None;, score=(train=0.028, test=0.043) total time=  13.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mike\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\layers\\core\\dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END nn__batch_size=16, nn__model__activation=relu, nn__model__dropout_rate=0.3, nn__model__learning_rate=0.002, nn__model__regularization=None;, score=(train=0.748, test=0.603) total time=  41.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mike\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\layers\\core\\dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END nn__batch_size=16, nn__model__activation=<LeakyReLU name=leaky_re_lu, built=True>, nn__model__dropout_rate=0.2, nn__model__learning_rate=0.0001, nn__model__regularization=l1_l2;, score=(train=0.996, test=0.797) total time= 2.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mike\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\layers\\core\\dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END nn__batch_size=16, nn__model__activation=<LeakyReLU name=leaky_re_lu, built=True>, nn__model__dropout_rate=0.2, nn__model__learning_rate=0.0001, nn__model__regularization=l1_l2;, score=(train=0.980, test=0.740) total time= 3.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mike\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\layers\\core\\dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END nn__batch_size=16, nn__model__activation=relu, nn__model__dropout_rate=0.3, nn__model__learning_rate=0.002, nn__model__regularization=l2;, score=(train=0.360, test=0.317) total time= 1.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mike\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\layers\\core\\dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END nn__batch_size=16, nn__model__activation=relu, nn__model__dropout_rate=0.3, nn__model__learning_rate=0.002, nn__model__regularization=l2;, score=(train=0.574, test=0.526) total time=  35.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mike\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\layers\\core\\dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END nn__batch_size=64, nn__model__activation=<LeakyReLU name=leaky_re_lu, built=True>, nn__model__dropout_rate=0.4, nn__model__learning_rate=0.002, nn__model__regularization=l1_l2;, score=(train=0.488, test=0.406) total time=  16.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mike\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\layers\\core\\dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END nn__batch_size=64, nn__model__activation=<LeakyReLU name=leaky_re_lu, built=True>, nn__model__dropout_rate=0.4, nn__model__learning_rate=0.002, nn__model__regularization=l1_l2;, score=(train=0.846, test=0.693) total time=  27.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mike\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\layers\\core\\dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END nn__batch_size=128, nn__model__activation=relu, nn__model__dropout_rate=0.1, nn__model__learning_rate=0.0001, nn__model__regularization=l1_l2;, score=(train=0.923, test=0.818) total time=  32.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mike\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\layers\\core\\dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END nn__batch_size=128, nn__model__activation=relu, nn__model__dropout_rate=0.1, nn__model__learning_rate=0.0001, nn__model__regularization=l1_l2;, score=(train=0.968, test=0.706) total time=  33.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mike\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\layers\\core\\dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END nn__batch_size=16, nn__model__activation=<LeakyReLU name=leaky_re_lu, built=True>, nn__model__dropout_rate=0.1, nn__model__learning_rate=0.0001, nn__model__regularization=l1;, score=(train=0.992, test=0.811) total time= 1.9min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mike\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\layers\\core\\dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END nn__batch_size=16, nn__model__activation=<LeakyReLU name=leaky_re_lu, built=True>, nn__model__dropout_rate=0.1, nn__model__learning_rate=0.0001, nn__model__regularization=l1;, score=(train=0.973, test=0.732) total time= 1.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mike\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\layers\\core\\dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END nn__batch_size=128, nn__model__activation=<LeakyReLU name=leaky_re_lu, built=True>, nn__model__dropout_rate=0.1, nn__model__learning_rate=0.0001, nn__model__regularization=l1_l2;, score=(train=0.899, test=0.757) total time=  32.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mike\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\layers\\core\\dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END nn__batch_size=128, nn__model__activation=<LeakyReLU name=leaky_re_lu, built=True>, nn__model__dropout_rate=0.1, nn__model__learning_rate=0.0001, nn__model__regularization=l1_l2;, score=(train=0.984, test=0.733) total time=  33.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mike\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\layers\\core\\dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END nn__batch_size=64, nn__model__activation=relu, nn__model__dropout_rate=0.1, nn__model__learning_rate=1e-06, nn__model__regularization=l2;, score=(train=0.722, test=0.742) total time=  42.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mike\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\layers\\core\\dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END nn__batch_size=64, nn__model__activation=relu, nn__model__dropout_rate=0.1, nn__model__learning_rate=1e-06, nn__model__regularization=l2;, score=(train=0.704, test=0.561) total time=  47.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mike\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\layers\\core\\dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END nn__batch_size=64, nn__model__activation=<LeakyReLU name=leaky_re_lu, built=True>, nn__model__dropout_rate=0.1, nn__model__learning_rate=0.001, nn__model__regularization=l1_l2;, score=(train=0.912, test=0.798) total time=  20.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mike\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\layers\\core\\dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END nn__batch_size=64, nn__model__activation=<LeakyReLU name=leaky_re_lu, built=True>, nn__model__dropout_rate=0.1, nn__model__learning_rate=0.001, nn__model__regularization=l1_l2;, score=(train=0.940, test=0.741) total time=  24.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mike\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\layers\\core\\dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "SEARCH COMPLETE!\n",
      "================================================================================\n",
      "\n",
      "Total time: 96.18 minutes\n",
      "\n",
      "Best parameters found:\n",
      "  nn__model__regularization: l2\n",
      "  nn__model__learning_rate: 0.0001\n",
      "  nn__model__dropout_rate: 0.4\n",
      "  nn__model__activation: <LeakyReLU name=leaky_re_lu, built=True>\n",
      "  nn__batch_size: 32\n",
      "\n",
      "Best cross-validation accuracy: 0.7740\n",
      "Test set accuracy: 0.8091\n",
      "\n",
      "================================================================================\n",
      "TOP 10 CONFIGURATIONS:\n",
      "================================================================================\n",
      "\n",
      "Rank 1:\n",
      "  Accuracy: 0.7740 (+/- 0.0323)\n",
      "  Parameters: {'nn__model__regularization': 'l2', 'nn__model__learning_rate': 0.0001, 'nn__model__dropout_rate': 0.4, 'nn__model__activation': <LeakyReLU name=leaky_re_lu, built=True>, 'nn__batch_size': 32}\n",
      "\n",
      "Rank 2:\n",
      "  Accuracy: 0.7716 (+/- 0.0394)\n",
      "  Parameters: {'nn__model__regularization': 'l1', 'nn__model__learning_rate': 0.0001, 'nn__model__dropout_rate': 0.1, 'nn__model__activation': <LeakyReLU name=leaky_re_lu, built=True>, 'nn__batch_size': 16}\n",
      "\n",
      "Rank 3:\n",
      "  Accuracy: 0.7695 (+/- 0.0288)\n",
      "  Parameters: {'nn__model__regularization': 'l1_l2', 'nn__model__learning_rate': 0.001, 'nn__model__dropout_rate': 0.1, 'nn__model__activation': <LeakyReLU name=leaky_re_lu, built=True>, 'nn__batch_size': 64}\n",
      "\n",
      "Rank 4:\n",
      "  Accuracy: 0.7688 (+/- 0.0285)\n",
      "  Parameters: {'nn__model__regularization': 'l1_l2', 'nn__model__learning_rate': 0.0001, 'nn__model__dropout_rate': 0.2, 'nn__model__activation': <LeakyReLU name=leaky_re_lu, built=True>, 'nn__batch_size': 16}\n",
      "\n",
      "Rank 5:\n",
      "  Accuracy: 0.7622 (+/- 0.0563)\n",
      "  Parameters: {'nn__model__regularization': 'l1_l2', 'nn__model__learning_rate': 0.0001, 'nn__model__dropout_rate': 0.1, 'nn__model__activation': 'relu', 'nn__batch_size': 128}\n",
      "\n",
      "Rank 6:\n",
      "  Accuracy: 0.7597 (+/- 0.0324)\n",
      "  Parameters: {'nn__model__regularization': None, 'nn__model__learning_rate': 0.0001, 'nn__model__dropout_rate': 0.2, 'nn__model__activation': 'relu', 'nn__batch_size': 128}\n",
      "\n",
      "Rank 7:\n",
      "  Accuracy: 0.7572 (+/- 0.0229)\n",
      "  Parameters: {'nn__model__regularization': 'l1', 'nn__model__learning_rate': 1e-05, 'nn__model__dropout_rate': 0.5, 'nn__model__activation': <LeakyReLU name=leaky_re_lu, built=True>, 'nn__batch_size': 32}\n",
      "\n",
      "Rank 8:\n",
      "  Accuracy: 0.7544 (+/- 0.0483)\n",
      "  Parameters: {'nn__model__regularization': 'l2', 'nn__model__learning_rate': 0.0001, 'nn__model__dropout_rate': 0.1, 'nn__model__activation': <LeakyReLU name=leaky_re_lu, built=True>, 'nn__batch_size': 16}\n",
      "\n",
      "Rank 9:\n",
      "  Accuracy: 0.7528 (+/- 0.0455)\n",
      "  Parameters: {'nn__model__regularization': 'l1', 'nn__model__learning_rate': 0.0001, 'nn__model__dropout_rate': 0.1, 'nn__model__activation': 'tanh', 'nn__batch_size': 64}\n",
      "\n",
      "Rank 10:\n",
      "  Accuracy: 0.7506 (+/- 0.0175)\n",
      "  Parameters: {'nn__model__regularization': None, 'nn__model__learning_rate': 0.0001, 'nn__model__dropout_rate': 0.3, 'nn__model__activation': <LeakyReLU name=leaky_re_lu, built=True>, 'nn__batch_size': 128}\n",
      "\n",
      "================================================================================\n",
      "Full results saved to 'nn_hyperparameter_search_results.csv'\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from tensorflow.keras.regularizers import l1, l2, l1_l2\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from keras.layers import LeakyReLU, Softmax, ReLU, BatchNormalization, Input, Activation\n",
    "from keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Split data FIRST\n",
    "X_train = pd.read_csv(\"X_train.csv\").values\n",
    "X_test = pd.read_csv(\"X_test.csv\").values\n",
    "y_train = pd.read_csv(\"y_train.csv\").values.ravel()\n",
    "y_test = pd.read_csv(\"y_test.csv\").values.ravel()\n",
    "\n",
    "# Label encode\n",
    "le = LabelEncoder()\n",
    "y_train_enc = le.fit_transform(y_train)\n",
    "y_test_enc = le.transform(y_test)\n",
    "\n",
    "# Get number of classes and input dimension\n",
    "n_classes = len(np.unique(y_train_enc))\n",
    "input_dim = X_train.shape[1]\n",
    "\n",
    "print(f\"Input dimensions: {input_dim}\")\n",
    "print(f\"Number of classes: {n_classes}\")\n",
    "\n",
    "# Create function to build neural network with more options\n",
    "def create_nn(meta, neurons_layer1=256, neurons_layer2=128, dropout_rate1=0.2, dropout_rate2=0.3, \n",
    "              learning_rate=0.002, activation='relu', regularization=None):\n",
    "    \n",
    "    # Set regularizer\n",
    "    if regularization == 'l1':\n",
    "        reg = l1(1e-15)\n",
    "    elif regularization == 'l2':\n",
    "        reg = l2(1e-15)\n",
    "    elif regularization == 'l1_l2':\n",
    "        reg = l1_l2(l1=1e-15, l2=1e-15)\n",
    "    else:\n",
    "        reg = None\n",
    "\n",
    "    # Get input dimensions from meta\n",
    "    n_features_in = meta[\"n_features_in_\"]\n",
    "    n_classes = meta[\"n_classes_\"]\n",
    "    \n",
    "    # Build model\n",
    "    model = Sequential([\n",
    "        Dense(neurons_layer1, activation=activation, kernel_regularizer=reg, \n",
    "              input_shape=(n_features_in,)),  # Adjust based on feature selection\n",
    "        Dropout(dropout_rate1),\n",
    "        Dense(neurons_layer2, activation=activation, kernel_regularizer=reg),\n",
    "        Dropout(dropout_rate2),\n",
    "        Dense(n_classes, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Wrap model\n",
    "nn_model = KerasClassifier(\n",
    "    model=create_nn, \n",
    "    epochs=100, \n",
    "    batch_size=16, \n",
    "    verbose=0,\n",
    "    callbacks=[EarlyStopping(monitor='loss', patience=10, restore_best_weights=True)]\n",
    ")\n",
    "\n",
    "# Pipeline with feature selection\n",
    "pipeline = ImbPipeline([\n",
    "    ('smote', SMOTE(random_state=seed)),\n",
    "    ('nn', nn_model)\n",
    "])\n",
    "\n",
    "# Parameter grid based on the paper\n",
    "param_grid = {\n",
    "    # Best from paper: None, ReLU, 0.002, 16, 0.3\n",
    "    'nn__model__regularization': [None, 'l1', 'l2', 'l1_l2'],\n",
    "    'nn__model__activation': ['relu', 'tanh', LeakyReLU(negative_slope=0.01)],\n",
    "    'nn__model__learning_rate': [0.01, 0.002, 0.001, 0.0001, 0.00001, 0.000001],\n",
    "    'nn__batch_size': [16, 32, 64, 128],\n",
    "    'nn__model__dropout_rate': [0.1, 0.2, 0.3, 0.4, 0.5],\n",
    "    #'nn__model__neurons_layer1': [128, 256],  # Not in paper but good to test\n",
    "    #'nn__model__neurons_layer2': [64, 128]\n",
    "}\n",
    "\n",
    "# Use RandomizedSearchCV to sample combinations\n",
    "print(\"Starting hyperparameter search...\")\n",
    "print(f\"Total possible combinations: {4 * 3 * 6 * 4 * 5 * 2 * 2} = {4*3*6*4*5*2*2}\")\n",
    "print(\"Testing 50 random combinations with 3-fold CV = 150 model trainings\\n\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "grid_search = RandomizedSearchCV(\n",
    "    estimator=pipeline,\n",
    "    param_distributions=param_grid,\n",
    "    n_iter=50,  # Test 50 random combinations\n",
    "    cv=2,  # 3-fold CV (paper uses 5-fold, but 3 is faster)\n",
    "    scoring='f1_weighted',\n",
    "    n_jobs=1,  # Use 1 to avoid issues with Keras\n",
    "    verbose=3,  # Maximum verbosity for progress tracking\n",
    "    random_state=seed,\n",
    "    return_train_score=True\n",
    ")\n",
    "\n",
    "# Fit with progress tracking\n",
    "grid_search.fit(X_train, y_train_enc)\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = (end_time - start_time) / 60  # Convert to minutes\n",
    "\n",
    "# Results\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SEARCH COMPLETE!\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nTotal time: {elapsed_time:.2f} minutes\")\n",
    "print(f\"\\nBest parameters found:\")\n",
    "for param, value in grid_search.best_params_.items():\n",
    "    print(f\"  {param}: {value}\")\n",
    "print(f\"\\nBest cross-validation accuracy: {grid_search.best_score_:.4f}\")\n",
    "\n",
    "# Test on held-out test set\n",
    "test_acc = grid_search.score(X_test, y_test_enc)\n",
    "print(f\"Test set accuracy: {test_acc:.4f}\")\n",
    "\n",
    "# Create results dataframe\n",
    "results_df = pd.DataFrame(grid_search.cv_results_)\n",
    "results_df = results_df.sort_values('rank_test_score')\n",
    "\n",
    "# Show top 10 configurations\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TOP 10 CONFIGURATIONS:\")\n",
    "print(\"=\"*80)\n",
    "top_10 = results_df[['params', 'mean_test_score', 'std_test_score', 'rank_test_score']].head(10)\n",
    "for idx, row in top_10.iterrows():\n",
    "    print(f\"\\nRank {int(row['rank_test_score'])}:\")\n",
    "    print(f\"  Accuracy: {row['mean_test_score']:.4f} (+/- {row['std_test_score']:.4f})\")\n",
    "    print(f\"  Parameters: {row['params']}\")\n",
    "\n",
    "# Save results to CSV\n",
    "results_df.to_csv('nn_hyperparameter_search_results.csv', index=False)\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Full results saved to 'nn_hyperparameter_search_results.csv'\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "184c023a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input dimensions: 19277\n",
      "Number of classes: 5\n",
      "Starting direct test of specific hyperparameters...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "\nAll the 2 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n2 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\mike\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\model_selection\\_validation.py\", line 859, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\mike\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\base.py\", line 1365, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\mike\\AppData\\Roaming\\Python\\Python311\\site-packages\\imblearn\\pipeline.py\", line 526, in fit\n    self._final_estimator.fit(Xt, yt, **last_step_params[\"fit\"])\n  File \"C:\\Users\\mike\\AppData\\Roaming\\Python\\Python311\\site-packages\\scikeras\\wrappers.py\", line 1501, in fit\n    super().fit(X=X, y=y, sample_weight=sample_weight, **kwargs)\n  File \"C:\\Users\\mike\\AppData\\Roaming\\Python\\Python311\\site-packages\\scikeras\\wrappers.py\", line 770, in fit\n    self._fit(\n  File \"C:\\Users\\mike\\AppData\\Roaming\\Python\\Python311\\site-packages\\scikeras\\wrappers.py\", line 925, in _fit\n    X, y = self._initialize(X, y)\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\mike\\AppData\\Roaming\\Python\\Python311\\site-packages\\scikeras\\wrappers.py\", line 862, in _initialize\n    self.model_ = self._build_keras_model()\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\mike\\AppData\\Roaming\\Python\\Python311\\site-packages\\scikeras\\wrappers.py\", line 433, in _build_keras_model\n    model = final_build_fn(**build_params)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\mike\\AppData\\Local\\Temp\\ipykernel_119008\\1124579009.py\", line 75, in create_nn\n    model = Sequential([\n           ^^^^^^^^^^\nNameError: name 'Sequential' is not defined\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 117\u001b[39m\n\u001b[32m    114\u001b[39m start_time = time.time()\n\u001b[32m    116\u001b[39m \u001b[38;5;66;03m# 3. Use cross_val_score to evaluate the specific configuration\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m cv_scores = \u001b[43mcross_val_score\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpipeline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    119\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    120\u001b[39m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m=\u001b[49m\u001b[43my_train_enc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    121\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcv\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# Use the same CV as your RandomizedSearchCV\u001b[39;49;00m\n\u001b[32m    122\u001b[39m \u001b[43m    \u001b[49m\u001b[43mscoring\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mf1_weighted\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    123\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    124\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m \u001b[49m\n\u001b[32m    125\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m    127\u001b[39m end_time = time.time()\n\u001b[32m    128\u001b[39m elapsed_time = (end_time - start_time) / \u001b[32m60\u001b[39m \n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\utils\\_param_validation.py:218\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    212\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    213\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m    214\u001b[39m         skip_parameter_validation=(\n\u001b[32m    215\u001b[39m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m    216\u001b[39m         )\n\u001b[32m    217\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m218\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    220\u001b[39m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[32m    222\u001b[39m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[32m    224\u001b[39m     msg = re.sub(\n\u001b[32m    225\u001b[39m         \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[33m\\\u001b[39m\u001b[33mw+ must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    226\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    227\u001b[39m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[32m    228\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\model_selection\\_validation.py:677\u001b[39m, in \u001b[36mcross_val_score\u001b[39m\u001b[34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, params, pre_dispatch, error_score)\u001b[39m\n\u001b[32m    674\u001b[39m \u001b[38;5;66;03m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[32m    675\u001b[39m scorer = check_scoring(estimator, scoring=scoring)\n\u001b[32m--> \u001b[39m\u001b[32m677\u001b[39m cv_results = \u001b[43mcross_validate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    678\u001b[39m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m=\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    679\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    680\u001b[39m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m=\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    681\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    682\u001b[39m \u001b[43m    \u001b[49m\u001b[43mscoring\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mscore\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    683\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcv\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    684\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    685\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    686\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    687\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpre_dispatch\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpre_dispatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    688\u001b[39m \u001b[43m    \u001b[49m\u001b[43merror_score\u001b[49m\u001b[43m=\u001b[49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    689\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    690\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m cv_results[\u001b[33m\"\u001b[39m\u001b[33mtest_score\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\utils\\_param_validation.py:218\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    212\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    213\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m    214\u001b[39m         skip_parameter_validation=(\n\u001b[32m    215\u001b[39m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m    216\u001b[39m         )\n\u001b[32m    217\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m218\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    220\u001b[39m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[32m    222\u001b[39m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[32m    224\u001b[39m     msg = re.sub(\n\u001b[32m    225\u001b[39m         \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[33m\\\u001b[39m\u001b[33mw+ must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    226\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    227\u001b[39m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[32m    228\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\model_selection\\_validation.py:419\u001b[39m, in \u001b[36mcross_validate\u001b[39m\u001b[34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001b[39m\n\u001b[32m    398\u001b[39m parallel = Parallel(n_jobs=n_jobs, verbose=verbose, pre_dispatch=pre_dispatch)\n\u001b[32m    399\u001b[39m results = parallel(\n\u001b[32m    400\u001b[39m     delayed(_fit_and_score)(\n\u001b[32m    401\u001b[39m         clone(estimator),\n\u001b[32m   (...)\u001b[39m\u001b[32m    416\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m train, test \u001b[38;5;129;01min\u001b[39;00m indices\n\u001b[32m    417\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m419\u001b[39m \u001b[43m_warn_or_raise_about_fit_failures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresults\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_score\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    421\u001b[39m \u001b[38;5;66;03m# For callable scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[32m    422\u001b[39m \u001b[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[32m    423\u001b[39m \u001b[38;5;66;03m# the correct key.\u001b[39;00m\n\u001b[32m    424\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(scoring):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\model_selection\\_validation.py:505\u001b[39m, in \u001b[36m_warn_or_raise_about_fit_failures\u001b[39m\u001b[34m(results, error_score)\u001b[39m\n\u001b[32m    498\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m num_failed_fits == num_fits:\n\u001b[32m    499\u001b[39m     all_fits_failed_message = (\n\u001b[32m    500\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mAll the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m fits failed.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    501\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mIt is very likely that your model is misconfigured.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    502\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mYou can try to debug the error by setting error_score=\u001b[39m\u001b[33m'\u001b[39m\u001b[33mraise\u001b[39m\u001b[33m'\u001b[39m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    503\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    504\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m505\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[32m    507\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    508\u001b[39m     some_fits_failed_message = (\n\u001b[32m    509\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mnum_failed_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m fits failed out of a total of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    510\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mThe score on these train-test partitions for these parameters\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    514\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    515\u001b[39m     )\n",
      "\u001b[31mValueError\u001b[39m: \nAll the 2 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n2 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\mike\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\model_selection\\_validation.py\", line 859, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\mike\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\base.py\", line 1365, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\mike\\AppData\\Roaming\\Python\\Python311\\site-packages\\imblearn\\pipeline.py\", line 526, in fit\n    self._final_estimator.fit(Xt, yt, **last_step_params[\"fit\"])\n  File \"C:\\Users\\mike\\AppData\\Roaming\\Python\\Python311\\site-packages\\scikeras\\wrappers.py\", line 1501, in fit\n    super().fit(X=X, y=y, sample_weight=sample_weight, **kwargs)\n  File \"C:\\Users\\mike\\AppData\\Roaming\\Python\\Python311\\site-packages\\scikeras\\wrappers.py\", line 770, in fit\n    self._fit(\n  File \"C:\\Users\\mike\\AppData\\Roaming\\Python\\Python311\\site-packages\\scikeras\\wrappers.py\", line 925, in _fit\n    X, y = self._initialize(X, y)\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\mike\\AppData\\Roaming\\Python\\Python311\\site-packages\\scikeras\\wrappers.py\", line 862, in _initialize\n    self.model_ = self._build_keras_model()\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\mike\\AppData\\Roaming\\Python\\Python311\\site-packages\\scikeras\\wrappers.py\", line 433, in _build_keras_model\n    model = final_build_fn(**build_params)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\mike\\AppData\\Local\\Temp\\ipykernel_119008\\1124579009.py\", line 75, in create_nn\n    model = Sequential([\n           ^^^^^^^^^^\nNameError: name 'Sequential' is not defined\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from tensorflow.keras.regularizers import l1, l2, l1_l2\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from keras.layers import LeakyReLU, Softmax, ReLU, BatchNormalization, Input, Activation\n",
    "from keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# ... (rest of your imports)\n",
    "\n",
    "# Assuming 'seed' is defined globally as in your original script\n",
    "seed = 42 \n",
    "\n",
    "# Split data FIRST\n",
    "X_train = pd.read_csv(\"X_train.csv\").values\n",
    "X_test = pd.read_csv(\"X_test.csv\").values\n",
    "y_train = pd.read_csv(\"y_train.csv\").values.ravel()\n",
    "y_test = pd.read_csv(\"y_test.csv\").values.ravel()\n",
    "\n",
    "# Label encode\n",
    "le = LabelEncoder()\n",
    "y_train_enc = le.fit_transform(y_train)\n",
    "y_test_enc = le.transform(y_test)\n",
    "\n",
    "# Get number of classes and input dimension\n",
    "n_classes = len(np.unique(y_train_enc))\n",
    "input_dim = X_train.shape[1]\n",
    "\n",
    "print(f\"Input dimensions: {input_dim}\")\n",
    "print(f\"Number of classes: {n_classes}\")\n",
    "\n",
    "# --- Specific Hyperparameter Set to Test (from your output) ---\n",
    "# NOTE: LeakyReLU needs to be instantiated correctly.\n",
    "specific_params = {\n",
    "    'nn__model__regularization': 'l2', \n",
    "    'nn__model__learning_rate': 0.0001, \n",
    "    'nn__model__dropout_rate': 0.4, \n",
    "    'nn__model__activation': LeakyReLU(negative_slope=0.01), # Instantiate LeakyReLU\n",
    "    'nn__batch_size': 32\n",
    "}\n",
    "# -----------------------------------------------------------\n",
    "\n",
    "\n",
    "# Create function to build neural network with more options (Keep this function)\n",
    "def create_nn(meta, neurons_layer1=256, neurons_layer2=128, dropout_rate=0.3, \n",
    "              learning_rate=0.002, activation='relu', regularization=None):\n",
    "    \n",
    "    # Set regularizer\n",
    "    if regularization == 'l1':\n",
    "        reg = l1(1e-15)\n",
    "    elif regularization == 'l2':\n",
    "        reg = l2(1e-15)\n",
    "    elif regularization == 'l1_l2':\n",
    "        reg = l1_l2(l1=1e-15, l2=1e-15)\n",
    "    else:\n",
    "        reg = None\n",
    "\n",
    "    # Get input dimensions from meta\n",
    "    n_features_in = meta[\"n_features_in_\"]\n",
    "    n_classes = meta[\"n_classes_\"]\n",
    "    \n",
    "    # Build model (Ensuring Sequential is used and imported)\n",
    "    model = Sequential([ \n",
    "        Dense(neurons_layer1, activation=activation, kernel_regularizer=reg, \n",
    "              input_shape=(n_features_in,)),\n",
    "        Dropout(dropout_rate),\n",
    "        Dense(neurons_layer2, activation=activation, kernel_regularizer=reg),\n",
    "        Dropout(dropout_rate),\n",
    "        Dense(n_classes, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Wrap model with default/placeholder values first\n",
    "nn_model = KerasClassifier(\n",
    "    model=create_nn, \n",
    "    epochs=100, \n",
    "    batch_size=16, \n",
    "    verbose=0,\n",
    "    callbacks=[EarlyStopping(monitor='loss', patience=10, restore_best_weights=True)]\n",
    ")\n",
    "\n",
    "# Pipeline with feature selection (Keep this pipeline)\n",
    "pipeline = ImbPipeline([\n",
    "    ('smote', SMOTE(random_state=seed)),\n",
    "    ('nn', nn_model)\n",
    "])\n",
    "\n",
    "\n",
    "# --- APPLY SPECIFIC HYPERPARAMETERS AND TEST DIRECTLY ---\n",
    "print(\"Starting direct test of specific hyperparameters...\")\n",
    "\n",
    "# 1. Set the specific parameters on the pipeline\n",
    "pipeline.set_params(**specific_params)\n",
    "\n",
    "# 2. Get the new nn_model with updated parameters (This step is often implicit in sklearn, \n",
    "# but setting on the pipeline ensures the new KerasClassifier wrapper is used.)\n",
    "# Note: The KerasClassifier model is rebuilt inside the cross_val_score process.\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# 3. Use cross_val_score to evaluate the specific configuration\n",
    "cv_scores = cross_val_score(\n",
    "    estimator=pipeline,\n",
    "    X=X_train,\n",
    "    y=y_train_enc,\n",
    "    cv=2, # Use the same CV as your RandomizedSearchCV\n",
    "    scoring='f1_weighted',\n",
    "    n_jobs=1,\n",
    "    verbose=0 \n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = (end_time - start_time) / 60 \n",
    "\n",
    "# Results\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SPECIFIC HYPERPARAMETER TEST COMPLETE!\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nTotal time: {elapsed_time:.2f} minutes\")\n",
    "print(f\"\\nTested parameters:\")\n",
    "for param, value in specific_params.items():\n",
    "    print(f\"  {param}: {value}\")\n",
    "print(f\"\\nCross-validation F1-Weighted Scores (CV={2}): {cv_scores}\")\n",
    "print(f\"Mean cross-validation F1-Weighted Score: {np.mean(cv_scores):.4f}\")\n",
    "print(f\"Standard Deviation of CV Score: {np.std(cv_scores):.4f}\")\n",
    "\n",
    "# Train final model on the whole training set and test on held-out test set\n",
    "print(\"\\nTraining final model on full training set...\")\n",
    "pipeline.fit(X_train, y_train_enc)\n",
    "test_score = pipeline.score(X_test, y_test_enc)\n",
    "\n",
    "print(f\"Test set F1-Weighted Score: {test_score:.4f}\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0b259a70-a26e-4a15-a69f-1e5cc07743da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Accuracy (Best Neural Network): 0.1694\n",
      "\n",
      "Classification Report (Best Neural Network):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Basal       1.00      0.06      0.11        17\n",
      "        Her2       0.06      1.00      0.12         7\n",
      "        LumA       0.00      0.00      0.00        58\n",
      "        LumB       0.00      0.00      0.00        25\n",
      "      Normal       0.87      0.76      0.81        17\n",
      "\n",
      "    accuracy                           0.17       124\n",
      "   macro avg       0.39      0.36      0.21       124\n",
      "weighted avg       0.26      0.17      0.13       124\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mike\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "C:\\Users\\mike\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "C:\\Users\\mike\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Retraining best model to visualize training history...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Pipeline.fit does not accept the validation_split parameter. You can pass parameters to specific steps of your pipeline using the stepname__parameter format, e.g. `Pipeline.fit(X, y, logisticregression__sample_weight=sample_weight)`.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 61\u001b[39m\n\u001b[32m     33\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mRetraining best model to visualize training history...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     35\u001b[39m \u001b[38;5;66;03m# best_params = grid_search.best_params_\u001b[39;00m\n\u001b[32m     36\u001b[39m \n\u001b[32m     37\u001b[39m \u001b[38;5;66;03m#meta = {\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     58\u001b[39m \u001b[38;5;66;03m#    callbacks=[EarlyStopping(monitor='loss', patience=10, restore_best_weights=True)]\u001b[39;00m\n\u001b[32m     59\u001b[39m \u001b[38;5;66;03m#)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m61\u001b[39m history = \u001b[43mpipeline\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_enc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     62\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     63\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     64\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     65\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mEarlyStopping\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmonitor\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mloss\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpatience\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrestore_best_weights\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m     66\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     68\u001b[39m \u001b[38;5;66;03m# Plot training & validation accuracy and loss\u001b[39;00m\n\u001b[32m     69\u001b[39m plt.figure(figsize=(\u001b[32m12\u001b[39m, \u001b[32m5\u001b[39m))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\base.py:1365\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1358\u001b[39m     estimator._validate_params()\n\u001b[32m   1360\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1361\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1362\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1363\u001b[39m     )\n\u001b[32m   1364\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1365\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\imblearn\\pipeline.py:517\u001b[39m, in \u001b[36mPipeline.fit\u001b[39m\u001b[34m(self, X, y, **params)\u001b[39m\n\u001b[32m    510\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m sklearn_version < parse_version(\u001b[33m\"\u001b[39m\u001b[33m1.4\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.transform_input \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    511\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    512\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mThe `transform_input` parameter is not supported in scikit-learn \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    513\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mversions prior to 1.4. Please upgrade to scikit-learn 1.4 or \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    514\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mlater.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    515\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m517\u001b[39m routed_params = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_check_method_params\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfit\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprops\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    518\u001b[39m Xt, yt = \u001b[38;5;28mself\u001b[39m._fit(X, y, routed_params, raw_params=params)\n\u001b[32m    519\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(\u001b[33m\"\u001b[39m\u001b[33mPipeline\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m._log_message(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.steps) - \u001b[32m1\u001b[39m)):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\imblearn\\pipeline.py:1257\u001b[39m, in \u001b[36mPipeline._check_method_params\u001b[39m\u001b[34m(self, method, props, **kwargs)\u001b[39m\n\u001b[32m   1255\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m pname, pval \u001b[38;5;129;01min\u001b[39;00m props.items():\n\u001b[32m   1256\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33m__\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pname:\n\u001b[32m-> \u001b[39m\u001b[32m1257\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1258\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mPipeline.fit does not accept the \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m parameter. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1259\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mYou can pass parameters to specific steps of your \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1260\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mpipeline using the stepname__parameter format, e.g. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1261\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33m`Pipeline.fit(X, y, logisticregression__sample_weight\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1262\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33m=sample_weight)`.\u001b[39m\u001b[33m\"\u001b[39m.format(pname)\n\u001b[32m   1263\u001b[39m         )\n\u001b[32m   1264\u001b[39m     step, param = pname.split(\u001b[33m\"\u001b[39m\u001b[33m__\u001b[39m\u001b[33m\"\u001b[39m, \u001b[32m1\u001b[39m)\n\u001b[32m   1265\u001b[39m     fit_params_steps[step][\u001b[33m\"\u001b[39m\u001b[33mfit\u001b[39m\u001b[33m\"\u001b[39m][param] = pval\n",
      "\u001b[31mValueError\u001b[39m: Pipeline.fit does not accept the validation_split parameter. You can pass parameters to specific steps of your pipeline using the stepname__parameter format, e.g. `Pipeline.fit(X, y, logisticregression__sample_weight=sample_weight)`."
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "# Evaluate on test set using best model from grid search\n",
    "# test_acc = grid_search.score(X_test, y_test_enc)\n",
    "test_acc = pipeline.score(X_test, y_test_enc)\n",
    "print(f\"\\nTest Accuracy (Best Neural Network): {test_acc:.4f}\")\n",
    "\n",
    "# Predict using best model\n",
    "# y_pred_classes = grid_search.predict(X_test)\n",
    "y_pred_classes = pipeline.predict(X_test)\n",
    "\n",
    "# Classification report\n",
    "print(\"\\nClassification Report (Best Neural Network):\")\n",
    "print(classification_report(y_test_enc, y_pred_classes, target_names=le.classes_))\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_test_enc, y_pred_classes)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=le.classes_,\n",
    "            yticklabels=le.classes_)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix - Best Neural Network from GridSearch')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nRetraining best model to visualize training history...\")\n",
    "\n",
    "# best_params = grid_search.best_params_\n",
    "\n",
    "#meta = {\n",
    "#    \"n_features_in_\": X_train.shape[1],\n",
    "#    \"n_classes_\": len(np.unique(y_train_enc))\n",
    "#}\n",
    "\n",
    "#best_model = create_nn(\n",
    "#    meta=meta,\n",
    "#    neurons_layer1=best_params.get('nn__model__neurons_layer1', 256),\n",
    "#    neurons_layer2=best_params.get('nn__model__neurons_layer2', 128),\n",
    "#    dropout_rate=best_params['nn__model__dropout_rate'],\n",
    "#    learning_rate=best_params['nn__model__learning_rate'],\n",
    "#    activation=best_params['nn__model__activation'],\n",
    "#    regularization=best_params['nn__model__regularization']\n",
    "#)\n",
    "\n",
    "#history = best_model.fit(\n",
    "#    X_train, y_train_enc,\n",
    "#    validation_split=0.2,\n",
    "#    epochs=100,\n",
    "#    batch_size=best_params['nn__batch_size'],\n",
    "#    verbose=0,\n",
    "#    callbacks=[EarlyStopping(monitor='loss', patience=10, restore_best_weights=True)]\n",
    "#)\n",
    "\n",
    "history = pipeline.fit( X_train, y_train_enc,\n",
    "    validation_split=0.2,\n",
    "    epochs=100,\n",
    "    verbose=0,\n",
    "    callbacks=[EarlyStopping(monitor='loss', patience=10, restore_best_weights=True)]\n",
    ")\n",
    "\n",
    "# Plot training & validation accuracy and loss\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Accuracy\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Training & Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "# Loss\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Training & Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# GridSearch Results Visualization\n",
    "# ------------------------------------------------------------------\n",
    "\n",
    "results_df = pd.DataFrame(grid_search.cv_results_)\n",
    "\n",
    "# Plot top 20 configurations\n",
    "plt.figure(figsize=(14, 6))\n",
    "top_20 = results_df.nsmallest(20, 'rank_test_score')\n",
    "\n",
    "plt.barh(range(len(top_20)), top_20['mean_test_score'], xerr=top_20['std_test_score'])\n",
    "plt.yticks(range(len(top_20)), [f\"Config {i+1}\" for i in range(len(top_20))])\n",
    "plt.xlabel('Mean CV Accuracy')\n",
    "plt.ylabel('Configuration')\n",
    "plt.title('Top 20 Hyperparameter Configurations (with std dev)')\n",
    "plt.axvline(x=grid_search.best_score_, color='r', linestyle='--', label=f'Best: {grid_search.best_score_:.4f}')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# Hyperparameter importance analysis\n",
    "# ------------------------------------------------------------------\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"HYPERPARAMETER ANALYSIS:\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "top_10_configs = results_df.nsmallest(10, 'rank_test_score')\n",
    "\n",
    "for param in ['nn__model__regularization', 'nn__model__activation', \n",
    "              'nn__model__learning_rate', 'nn__batch_size', 'nn__model__dropout_rate']:\n",
    "    print(f\"\\n{param}:\")\n",
    "    param_values = [config[param] for config in top_10_configs['params']]\n",
    "    counts = Counter(param_values)\n",
    "    for value, count in counts.most_common():\n",
    "        print(f\"  {value}: appears {count}/10 times in top 10\")\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# CV Accuracy Distribution\n",
    "# ------------------------------------------------------------------\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Histogram of all CV accuracies\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(results_df['mean_test_score'], bins=30, edgecolor='black', alpha=0.7)\n",
    "plt.axvline(x=grid_search.best_score_, color='r', linestyle='--', \n",
    "            label=f'Best: {grid_search.best_score_:.4f}')\n",
    "plt.xlabel('Mean CV Accuracy')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of CV Accuracies Across All Configurations')\n",
    "plt.legend()\n",
    "\n",
    "# Box plot (adjust to number of folds)\n",
    "plt.subplot(1, 2, 2)\n",
    "n_folds = pipeline.cv  # dynamically use actual folds\n",
    "cv_scores = [results_df[f'split{i}_test_score'] for i in range(n_folds)]\n",
    "plt.boxplot(cv_scores, labels=[f'Fold {i+1}' for i in range(n_folds)])\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('CV Accuracy Distribution per Fold')\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# Summary statistics\n",
    "# ------------------------------------------------------------------\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SUMMARY STATISTICS:\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Best CV Accuracy: {grid_search.best_score_:.4f}\")\n",
    "print(f\"Test Accuracy: {test_acc:.4f}\")\n",
    "print(f\"Mean CV Accuracy (all configs): {results_df['mean_test_score'].mean():.4f}\")\n",
    "print(f\"Std CV Accuracy (all configs): {results_df['mean_test_score'].std():.4f}\")\n",
    "print(f\"Min CV Accuracy: {results_df['mean_test_score'].min():.4f}\")\n",
    "print(f\"Max CV Accuracy: {results_df['mean_test_score'].max():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "92667640",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[MODEL] Extracting best Keras model...\n",
      "Using Keras model: <class 'keras.src.models.sequential.Sequential'>\n",
      "Model input shape: (None, 19277)\n",
      "Original data shape: (496, 19277)\n",
      "Total features: 19277\n",
      "\n",
      "[MEMORY] Reducing features from 19277 to 100 for SHAP analysis...\n",
      "  Method: Selecting high-variance features...\n",
      "  ✓ Reduced to 100 features\n",
      "  ✓ Memory footprint reduced by 99.5%\n",
      "  ✓ Selected features saved to selected_features_for_shap.csv\n",
      "SHAP analysis will use 100 features\n",
      "\n",
      "[SHAP] Background samples: 10\n",
      "[SHAP] Test samples: 10\n",
      "[SHAP] Creating model wrapper for feature expansion...\n",
      "\n",
      "[SHAP] Attempting DeepExplainer...\n",
      "  Note: DeepExplainer may not work well with feature reduction\n",
      "  Skipping to KernelExplainer...\n",
      "  ✗ DeepExplainer failed: Using KernelExplainer for feature reduction\n",
      "\n",
      "[SHAP] Using KernelExplainer with batch processing...\n",
      "  Processing batch 1/2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:01<?, ?it/s]\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 3.23 GiB for an array with shape (22480, 19277) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mException\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[35]\u001b[39m\u001b[32m, line 172\u001b[39m\n\u001b[32m    171\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m  Skipping to KernelExplainer...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m172\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mUsing KernelExplainer for feature reduction\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    174\u001b[39m explainer = shap.DeepExplainer(keras_model, small_bg)\n",
      "\u001b[31mException\u001b[39m: Using KernelExplainer for feature reduction",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mMemoryError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[35]\u001b[39m\u001b[32m, line 191\u001b[39m\n\u001b[32m    189\u001b[39m batch = small_test[i:batch_end]\n\u001b[32m    190\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m  Processing batch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi//SHAP_BATCH_SIZE\u001b[38;5;250m \u001b[39m+\u001b[38;5;250m \u001b[39m\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtotal_batches\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m191\u001b[39m batch_shap = \u001b[43mexplainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mshap_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    192\u001b[39m shap_values_list.append(batch_shap)\n\u001b[32m    193\u001b[39m gc.collect()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\shap\\explainers\\_kernel.py:275\u001b[39m, in \u001b[36mKernelExplainer.shap_values\u001b[39m\u001b[34m(self, X, **kwargs)\u001b[39m\n\u001b[32m    273\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.keep_index:\n\u001b[32m    274\u001b[39m     data = convert_to_instance_with_index(data, column_name, index_value[i : i + \u001b[32m1\u001b[39m], index_name)\n\u001b[32m--> \u001b[39m\u001b[32m275\u001b[39m explanations.append(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mexplain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    276\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m kwargs.get(\u001b[33m\"\u001b[39m\u001b[33mgc_collect\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[32m    277\u001b[39m     gc.collect()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\shap\\explainers\\_kernel.py:479\u001b[39m, in \u001b[36mKernelExplainer.explain\u001b[39m\u001b[34m(self, incoming_instance, **kwargs)\u001b[39m\n\u001b[32m    476\u001b[39m     \u001b[38;5;28mself\u001b[39m.kernelWeights[nfixed_samples:] *= weight_left / \u001b[38;5;28mself\u001b[39m.kernelWeights[nfixed_samples:].sum()\n\u001b[32m    478\u001b[39m \u001b[38;5;66;03m# execute the model on the synthetic samples we have created\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m479\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    481\u001b[39m \u001b[38;5;66;03m# solve then expand the feature importance (Shapley value) vector to contain the non-varying features\u001b[39;00m\n\u001b[32m    482\u001b[39m phi = np.zeros((\u001b[38;5;28mself\u001b[39m.data.groups_size, \u001b[38;5;28mself\u001b[39m.D))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\shap\\explainers\\_kernel.py:624\u001b[39m, in \u001b[36mKernelExplainer.run\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    622\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.keep_index_ordered:\n\u001b[32m    623\u001b[39m         data = data.sort_index()\n\u001b[32m--> \u001b[39m\u001b[32m624\u001b[39m modelOut = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    625\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(modelOut, (pd.DataFrame, pd.Series)):\n\u001b[32m    626\u001b[39m     modelOut = modelOut.values\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[35]\u001b[39m\u001b[32m, line 157\u001b[39m, in \u001b[36mmodel_wrapper_with_expansion\u001b[39m\u001b[34m(X_reduced)\u001b[39m\n\u001b[32m    155\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Expands reduced features to full input size with zeros for non-selected features\"\"\"\u001b[39;00m\n\u001b[32m    156\u001b[39m batch_size = X_reduced.shape[\u001b[32m0\u001b[39m]\n\u001b[32m--> \u001b[39m\u001b[32m157\u001b[39m X_full = \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mzeros\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moriginal_n_features\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    158\u001b[39m X_full[:, selected_feature_indices] = X_reduced\n\u001b[32m    159\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m keras_model.predict(X_full, batch_size=\u001b[32m32\u001b[39m, verbose=\u001b[32m0\u001b[39m)\n",
      "\u001b[31mMemoryError\u001b[39m: Unable to allocate 3.23 GiB for an array with shape (22480, 19277) and data type float64"
     ]
    }
   ],
   "source": [
    "import shap\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import gc\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# ==========================================\n",
    "# SETTINGS\n",
    "# ==========================================\n",
    "# Handle both DataFrame and numpy array inputs\n",
    "if isinstance(X_train, pd.DataFrame):\n",
    "    original_feature_names = X_train.columns.tolist()\n",
    "else:\n",
    "    # If numpy array, create generic feature names\n",
    "    original_feature_names = [f\"Feature_{i}\" for i in range(X_train.shape[1])]\n",
    "\n",
    "MAX_BACKGROUND = 10\n",
    "MAX_EXPLAIN = 10\n",
    "SHAP_BATCH_SIZE = 5  # Reduced for memory efficiency\n",
    "RANDOM_STATE = 42\n",
    "TOP_K = 10\n",
    "\n",
    "# MEMORY OPTIMIZATION: Reduce features for SHAP analysis\n",
    "# With 578K features, SHAP is computationally infeasible\n",
    "# Options: 'variance', 'model_weights', 'random', None\n",
    "FEATURE_REDUCTION = 'variance'  # Set to None to use all features (not recommended)\n",
    "MAX_FEATURES_FOR_SHAP = 100    # Number of features to keep for SHAP analysis\n",
    "\n",
    "# KernelExplainer settings (only used if DeepExplainer fails)\n",
    "KERNEL_NSAMPLES = 50  # Number of times to re-evaluate the model (lower = faster but less accurate)\n",
    "                       # Default is 2*n_features + 2048, which would be ~4000 for 1000 features\n",
    "                       # We use 100 for speed. Increase to 500-1000 for better accuracy.\n",
    "\n",
    "OUT_DIR = \"./explain_results\"\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "# ==========================================\n",
    "# MODEL EXTRACTION\n",
    "# ==========================================\n",
    "print(\"\\n[MODEL] Extracting best Keras model...\")\n",
    "keras_model = None\n",
    "try:\n",
    "    keras_model = getattr(pipeline, \"model_\", None)\n",
    "    if keras_model is None:\n",
    "        keras_model = pipeline.named_steps.get(\"nn\").model_\n",
    "except Exception:\n",
    "    keras_model = pipeline  # fallback\n",
    "\n",
    "if keras_model is None:\n",
    "    raise ValueError(\"Could not extract Keras model from best_model!\")\n",
    "\n",
    "print(\"Using Keras model:\", type(keras_model))\n",
    "print(f\"Model input shape: {keras_model.input_shape}\")\n",
    "\n",
    "# ==========================================\n",
    "# PREPARE DATA (GENE-LEVEL BETA VALUES)\n",
    "# ==========================================\n",
    "if isinstance(X_train, pd.DataFrame):\n",
    "    X_train_arr = X_train.values\n",
    "    X_test_arr = X_test.values\n",
    "else:\n",
    "    X_train_arr = X_train\n",
    "    X_test_arr = X_test\n",
    "\n",
    "print(f\"Original data shape: {X_train_arr.shape}\")\n",
    "print(f\"Total features: {len(original_feature_names)}\")\n",
    "\n",
    "# ==========================================\n",
    "# FEATURE REDUCTION FOR SHAP (MEMORY OPTIMIZATION)\n",
    "# ==========================================\n",
    "selected_feature_indices = None\n",
    "selected_feature_names = original_feature_names\n",
    "use_feature_reduction = False\n",
    "\n",
    "if FEATURE_REDUCTION and X_train_arr.shape[1] > MAX_FEATURES_FOR_SHAP:\n",
    "    print(f\"\\n[MEMORY] Reducing features from {X_train_arr.shape[1]} to {MAX_FEATURES_FOR_SHAP} for SHAP analysis...\")\n",
    "    use_feature_reduction = True\n",
    "    original_n_features = X_train_arr.shape[1]\n",
    "    \n",
    "    if FEATURE_REDUCTION == 'variance':\n",
    "        # Select features with highest variance\n",
    "        print(\"  Method: Selecting high-variance features...\")\n",
    "        feature_vars = np.var(X_train_arr, axis=0)\n",
    "        selected_feature_indices = np.argsort(feature_vars)[-MAX_FEATURES_FOR_SHAP:]\n",
    "        \n",
    "    elif FEATURE_REDUCTION == 'model_weights':\n",
    "        # Select features with highest absolute weights in first layer\n",
    "        print(\"  Method: Selecting features by model input weights...\")\n",
    "        first_layer_weights = keras_model.layers[0].get_weights()[0]  # Shape: (n_features, hidden_dim)\n",
    "        feature_importance = np.abs(first_layer_weights).sum(axis=1)\n",
    "        selected_feature_indices = np.argsort(feature_importance)[-MAX_FEATURES_FOR_SHAP:]\n",
    "        \n",
    "    elif FEATURE_REDUCTION == 'random':\n",
    "        # Random selection (for testing)\n",
    "        print(\"  Method: Random feature selection...\")\n",
    "        np.random.seed(RANDOM_STATE)\n",
    "        selected_feature_indices = np.random.choice(\n",
    "            X_train_arr.shape[1], \n",
    "            size=MAX_FEATURES_FOR_SHAP, \n",
    "            replace=False\n",
    "        )\n",
    "    \n",
    "    # Sort indices to maintain order\n",
    "    selected_feature_indices = sorted(selected_feature_indices)\n",
    "    selected_feature_names = [original_feature_names[i] for i in selected_feature_indices]\n",
    "    \n",
    "    # Store the reduced data separately for SHAP\n",
    "    X_train_reduced = X_train_arr[:, selected_feature_indices]\n",
    "    X_test_reduced = X_test_arr[:, selected_feature_indices]\n",
    "    \n",
    "    print(f\"  ✓ Reduced to {len(selected_feature_indices)} features\")\n",
    "    print(f\"  ✓ Memory footprint reduced by {100*(1 - MAX_FEATURES_FOR_SHAP/original_n_features):.1f}%\")\n",
    "    \n",
    "    # Save selected feature indices for reference\n",
    "    selected_df = pd.DataFrame({\n",
    "        'Original_Index': selected_feature_indices,\n",
    "        'Feature_Name': selected_feature_names\n",
    "    })\n",
    "    selected_df.to_csv(os.path.join(OUT_DIR, \"selected_features_for_shap.csv\"), index=False)\n",
    "    print(f\"  ✓ Selected features saved to selected_features_for_shap.csv\")\n",
    "else:\n",
    "    print(f\"\\n[INFO] Using all {X_train_arr.shape[1]} features for SHAP analysis\")\n",
    "    X_train_reduced = X_train_arr\n",
    "    X_test_reduced = X_test_arr\n",
    "\n",
    "print(f\"SHAP analysis will use {len(selected_feature_names)} features\")\n",
    "\n",
    "# ==========================================\n",
    "# SHAP EXPLANATIONS\n",
    "# ==========================================\n",
    "def shap_sample_fallback(X, n, random_state):\n",
    "    \"\"\"Sample data for SHAP background/explanation sets\"\"\"\n",
    "    if hasattr(shap, \"sample\"):\n",
    "        return shap.sample(X, n, random_state=random_state)\n",
    "    else:\n",
    "        idx = np.random.RandomState(random_state).choice(len(X), size=n, replace=False)\n",
    "        return X[idx]\n",
    "\n",
    "# Sample background and test data (using reduced features)\n",
    "small_bg = shap_sample_fallback(X_train_reduced, min(MAX_BACKGROUND, len(X_train_reduced)), RANDOM_STATE)\n",
    "small_test = shap_sample_fallback(X_test_reduced, min(MAX_EXPLAIN, len(X_test_reduced)), RANDOM_STATE)\n",
    "\n",
    "print(f\"\\n[SHAP] Background samples: {small_bg.shape[0]}\")\n",
    "print(f\"[SHAP] Test samples: {small_test.shape[0]}\")\n",
    "\n",
    "# Create a wrapper that expands reduced features back to full input\n",
    "if use_feature_reduction:\n",
    "    print(f\"[SHAP] Creating model wrapper for feature expansion...\")\n",
    "    \n",
    "    # Create a template with zeros for all features\n",
    "    def model_wrapper_with_expansion(X_reduced):\n",
    "        \"\"\"Expands reduced features to full input size with zeros for non-selected features\"\"\"\n",
    "        batch_size = X_reduced.shape[0]\n",
    "        X_full = np.zeros((batch_size, original_n_features))\n",
    "        X_full[:, selected_feature_indices] = X_reduced\n",
    "        return keras_model.predict(X_full, batch_size=32, verbose=0)\n",
    "    \n",
    "    model_wrapper = model_wrapper_with_expansion\n",
    "else:\n",
    "    def model_wrapper(X):\n",
    "        return keras_model.predict(X, batch_size=32, verbose=0)\n",
    "\n",
    "# Try DeepExplainer first, fall back to KernelExplainer\n",
    "try:\n",
    "    print(\"\\n[SHAP] Attempting DeepExplainer...\")\n",
    "    if use_feature_reduction:\n",
    "        print(\"  Note: DeepExplainer may not work well with feature reduction\")\n",
    "        print(\"  Skipping to KernelExplainer...\")\n",
    "        raise Exception(\"Using KernelExplainer for feature reduction\")\n",
    "    \n",
    "    explainer = shap.DeepExplainer(keras_model, small_bg)\n",
    "    shap_values = explainer.shap_values(small_test, check_additivity=False)\n",
    "    expected_value = explainer.expected_value\n",
    "    use_deep = True\n",
    "    print(\"  ✓ DeepExplainer successful\")\n",
    "except Exception as e:\n",
    "    print(f\"  ✗ DeepExplainer failed: {e}\")\n",
    "    print(\"\\n[SHAP] Using KernelExplainer with batch processing...\")\n",
    "    \n",
    "    explainer = shap.KernelExplainer(model_wrapper, small_bg)\n",
    "    shap_values_list = []\n",
    "    total_batches = int(np.ceil(len(small_test) / SHAP_BATCH_SIZE))\n",
    "    \n",
    "    for i in range(0, len(small_test), SHAP_BATCH_SIZE):\n",
    "        batch_end = min(i + SHAP_BATCH_SIZE, len(small_test))\n",
    "        batch = small_test[i:batch_end]\n",
    "        print(f\"  Processing batch {i//SHAP_BATCH_SIZE + 1}/{total_batches}...\")\n",
    "        batch_shap = explainer.shap_values(batch)\n",
    "        shap_values_list.append(batch_shap)\n",
    "        gc.collect()\n",
    "    \n",
    "    # Combine batches\n",
    "    if isinstance(shap_values_list[0], list):\n",
    "        n_classes = len(shap_values_list[0])\n",
    "        shap_values = [np.vstack([b[c] for b in shap_values_list]) for c in range(n_classes)]\n",
    "    else:\n",
    "        shap_values = np.vstack(shap_values_list)\n",
    "    \n",
    "    expected_value = explainer.expected_value\n",
    "    use_deep = False\n",
    "    print(\"  ✓ KernelExplainer successful\")\n",
    "\n",
    "del explainer\n",
    "gc.collect()\n",
    "\n",
    "# Convert list of arrays to 3D array if needed\n",
    "if isinstance(shap_values, list):\n",
    "    shap_values = np.stack([np.array(s) for s in shap_values], axis=2)\n",
    "\n",
    "print(f\"\\n[SHAP] SHAP values shape: {shap_values.shape}\")\n",
    "\n",
    "# ==========================================\n",
    "# OVERALL FEATURE IMPORTANCE\n",
    "# ==========================================\n",
    "print(\"\\n[SHAP] Computing overall feature importance...\")\n",
    "\n",
    "if shap_values.ndim == 3:\n",
    "    # Multi-class: take max absolute SHAP across classes\n",
    "    shap_values_overall = np.abs(shap_values).max(axis=2)\n",
    "else:\n",
    "    # Binary or regression\n",
    "    shap_values_overall = np.abs(shap_values)\n",
    "\n",
    "mean_abs_shap_overall = shap_values_overall.mean(axis=0)\n",
    "shap_importances_overall = pd.DataFrame({\n",
    "    \"Feature\": selected_feature_names,\n",
    "    \"MeanAbsSHAP_MaxAcrossClasses\": mean_abs_shap_overall\n",
    "}).sort_values(by=\"MeanAbsSHAP_MaxAcrossClasses\", ascending=False)\n",
    "\n",
    "top_features_overall = shap_importances_overall.head(TOP_K)\n",
    "top_features_overall.to_csv(os.path.join(OUT_DIR, \"top_features_overall.csv\"), index=False)\n",
    "\n",
    "# Plot overall importance\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.barplot(data=top_features_overall,\n",
    "            x=\"MeanAbsSHAP_MaxAcrossClasses\",\n",
    "            y=\"Feature\",\n",
    "            palette=\"Greens_d\")\n",
    "plt.title(f\"Top {TOP_K} Most Important Features (Overall)\")\n",
    "plt.xlabel(\"Mean |SHAP| Value\")\n",
    "plt.ylabel(\"Gene Feature\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(OUT_DIR, \"top10_overall_bar.png\"), dpi=150)\n",
    "plt.close()\n",
    "\n",
    "print(\"\\n=== Top 10 Most Important Features (Overall) ===\")\n",
    "print(top_features_overall)\n",
    "\n",
    "# ==========================================\n",
    "# EXTRACT CLASS LABELS\n",
    "# ==========================================\n",
    "try:\n",
    "    if hasattr(pipeline, 'classes_'):\n",
    "        class_names = pipeline.classes_.tolist()\n",
    "    elif hasattr(pipeline, 'named_steps') and 'nn' in pipeline.named_steps:\n",
    "        if hasattr(pipeline.named_steps['nn'], 'classes_'):\n",
    "            class_names = pipeline.named_steps['nn'].classes_.tolist()\n",
    "        else:\n",
    "            class_names = None\n",
    "    else:\n",
    "        class_names = None\n",
    "    \n",
    "    if class_names is None and 'y_train' in globals():\n",
    "        class_names = sorted(y_train.unique().tolist())\n",
    "    \n",
    "    print(f\"\\n[SHAP] Detected class names: {class_names}\")\n",
    "except Exception as e:\n",
    "    print(f\"[SHAP] Could not extract class names: {e}\")\n",
    "    class_names = None\n",
    "\n",
    "# ==========================================\n",
    "# PER-CLASS SHAP ANALYSIS\n",
    "# ==========================================\n",
    "if shap_values.ndim == 3:\n",
    "    n_classes = shap_values.shape[2]\n",
    "    print(f\"\\n[SHAP] Creating summary plots for {n_classes} classes...\")\n",
    "    \n",
    "    # Get original test data for plotting\n",
    "    if isinstance(X_test, pd.DataFrame):\n",
    "        X_test_original = X_test.values[:len(small_test)]\n",
    "    else:\n",
    "        X_test_original = X_test[:len(small_test)]\n",
    "    \n",
    "    # Extract only the selected features for plotting\n",
    "    if use_feature_reduction:\n",
    "        X_test_for_plot = X_test_original[:, selected_feature_indices]\n",
    "    else:\n",
    "        X_test_for_plot = X_test_original\n",
    "    \n",
    "    for class_idx in range(n_classes):\n",
    "        class_label = class_names[class_idx] if class_names else f\"Class {class_idx}\"\n",
    "        class_shap = shap_values[:, :, class_idx]\n",
    "        \n",
    "        print(f\"\\n  Processing {class_label}...\")\n",
    "        \n",
    "        # Summary plot (beeswarm) - Shows distribution of SHAP values\n",
    "        plt.figure(figsize=(12, 10))\n",
    "        shap.summary_plot(\n",
    "            class_shap,\n",
    "            X_test_for_plot,\n",
    "            feature_names=selected_feature_names,\n",
    "            max_display=TOP_K,\n",
    "            show=False\n",
    "        )\n",
    "        plt.title(f\"SHAP Summary Plot - {class_label}\", fontsize=14, pad=20)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(OUT_DIR, f\"shap_summary_{class_label.lower().replace(' ', '_')}.png\"), \n",
    "                   dpi=150, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        \n",
    "        # Bar plot (mean absolute SHAP) - Shows feature importance\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        shap.summary_plot(\n",
    "            class_shap,\n",
    "            X_test_for_plot,\n",
    "            feature_names=selected_feature_names,\n",
    "            max_display=TOP_K,\n",
    "            plot_type=\"bar\",\n",
    "            show=False\n",
    "        )\n",
    "        plt.title(f\"SHAP Feature Importance - {class_label}\", fontsize=14, pad=20)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(OUT_DIR, f\"shap_bar_{class_label.lower().replace(' ', '_')}.png\"), \n",
    "                   dpi=150, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        \n",
    "        # Save class-specific importance to CSV\n",
    "        mean_abs_shap_class = np.abs(class_shap).mean(axis=0)\n",
    "        class_importance = pd.DataFrame({\n",
    "            \"Feature\": selected_feature_names,\n",
    "            \"MeanAbsSHAP\": mean_abs_shap_class\n",
    "        }).sort_values(by=\"MeanAbsSHAP\", ascending=False)\n",
    "        class_importance.to_csv(\n",
    "            os.path.join(OUT_DIR, f\"top_features_{class_label.lower().replace(' ', '_')}.csv\"), \n",
    "            index=False\n",
    "        )\n",
    "        \n",
    "        print(f\"    Top 5 features for {class_label}:\")\n",
    "        print(class_importance.head(5).to_string(index=False))\n",
    "        print(f\"  ✓ {class_label} summary plots saved\")\n",
    "    \n",
    "    print(f\"\\n✓ Summary plots for all {n_classes} classes completed\")\n",
    "    \n",
    "else:\n",
    "    # Binary classification or regression\n",
    "    print(\"\\n[SHAP] Creating summary plots (single output)...\")\n",
    "    \n",
    "    if isinstance(X_test, pd.DataFrame):\n",
    "        X_test_original = X_test.values[:len(small_test)]\n",
    "    else:\n",
    "        X_test_original = X_test[:len(small_test)]\n",
    "    \n",
    "    # Extract only the selected features for plotting\n",
    "    if use_feature_reduction:\n",
    "        X_test_for_plot = X_test_original[:, selected_feature_indices]\n",
    "    else:\n",
    "        X_test_for_plot = X_test_original\n",
    "    \n",
    "    # Beeswarm plot\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    shap.summary_plot(\n",
    "        shap_values,\n",
    "        X_test_for_plot,\n",
    "        feature_names=selected_feature_names,\n",
    "        max_display=TOP_K,\n",
    "        show=False\n",
    "    )\n",
    "    plt.title(\"SHAP Summary Plot\", fontsize=14, pad=20)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(OUT_DIR, \"shap_summary.png\"), dpi=150, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # Bar plot\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    shap.summary_plot(\n",
    "        shap_values,\n",
    "        X_test_for_plot,\n",
    "        feature_names=selected_feature_names,\n",
    "        max_display=TOP_K,\n",
    "        plot_type=\"bar\",\n",
    "        show=False\n",
    "    )\n",
    "    plt.title(\"SHAP Feature Importance\", fontsize=14, pad=20)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(OUT_DIR, \"shap_bar.png\"), dpi=150, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    print(\"  ✓ Summary plots saved\")\n",
    "\n",
    "# ==========================================\n",
    "# SUMMARY\n",
    "# ==========================================\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"✅ SHAP ANALYSIS COMPLETE!\")\n",
    "print(\"=\"*50)\n",
    "print(f\"📁 Results saved to: {OUT_DIR}\")\n",
    "print(\"\\n📊 Generated files:\")\n",
    "print(\"   ✓ Overall feature importance (CSV + bar plot)\")\n",
    "if shap_values.ndim == 3:\n",
    "    print(f\"   ✓ Per-class summary plots (beeswarm + bar) for {n_classes} classes\")\n",
    "    print(f\"   ✓ Per-class feature importance CSVs for {n_classes} classes\")\n",
    "else:\n",
    "    print(\"   ✓ Summary plots (beeswarm + bar)\")\n",
    "print(\"\\n💡 Interpretation:\")\n",
    "print(\"   - Beeswarm plots show how feature values affect predictions\")\n",
    "print(\"   - Bar plots show overall feature importance by mean |SHAP|\")\n",
    "print(\"   - Red = high feature value, Blue = low feature value\")\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ebac44dd-af9f-4aab-acf7-430b3e7860c8",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Sequential' object has no attribute 'named_steps'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m rf = \u001b[43mbest_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnamed_steps\u001b[49m[\u001b[33m'\u001b[39m\u001b[33mrf\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(original_feature_names) != \u001b[38;5;28mlen\u001b[39m(rf.feature_importances_):\n\u001b[32m      4\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mWarning: Number of feature names (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(original_feature_names)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m) doesn\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt match number of features used (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(rf.feature_importances_)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m)\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mAttributeError\u001b[39m: 'Sequential' object has no attribute 'named_steps'"
     ]
    }
   ],
   "source": [
    "rf = best_model.named_steps['rf']\n",
    "\n",
    "if len(original_feature_names) != len(rf.feature_importances_):\n",
    "    print(f\"Warning: Number of feature names ({len(original_feature_names)}) doesn't match number of features used ({len(rf.feature_importances_)})\")\n",
    "    # Use generic names if there's a mismatch\n",
    "    feature_names = [f'Feature {i}' for i in range(len(rf.feature_importances_))]\n",
    "else:\n",
    "    feature_names = original_feature_names\n",
    "\n",
    "feature_importance = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Importance': rf.feature_importances_\n",
    "}).sort_values('Importance', ascending=False)\n",
    "\n",
    "# Display top 20 features\n",
    "top_n = 20\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.barplot(data=feature_importance.head(top_n), x='Importance', y='Feature')\n",
    "plt.title(f'Top {top_n} Most Important Features')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Top 20 features by importance:\")\n",
    "print(feature_importance['Feature'].head(20).tolist())"
   ]
  },
  {
   "cell_type": "raw",
   "id": "13a63ab1-bd35-4897-9ebc-edca8e28668a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6011b39-27ee-46f7-8b0e-aeb329bc7342",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
